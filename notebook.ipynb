{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "03c4f2befd112ae6133593a618d4cc9f49a940019336ec3e14700801b49563e8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import copy\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "state = 'fl_statewide.csv.zip'\n",
    "state2 = 'ca_long_beach_2020_04_01.csv'"
   ]
  },
  {
   "source": [
    "# Preprocessing whole dataset (do not execute if working on full data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(folder + state)\n",
    "print(df_full.columns)"
   ]
  },
  {
   "source": [
    "Reducing the amount of data for experimentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_file_path = folder + state.split('.')[0] + \"_cut.csv\"\n",
    "total_size = df_full.shape[0]\n",
    "df = df_full.sample(n=int(total_size/100))\n",
    "print(\"Full dataset of size {} was reduced to subset of {} elements.\".format(total_size, df.shape[0]))\n",
    "df.to_csv(cut_file_path, index = False)"
   ]
  },
  {
   "source": [
    "# Load the data (currently loading all data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df =  pd.read_csv(folder + state)\n",
    "print(\"Dataset is composed of {} stops. Columns are: \\n\".format(df.shape[0]))\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] != np.float64:\n",
    "        val = df[col].unique()\n",
    "        if len(val) > 20:\n",
    "            print('{} \\t\\t: too much different values'.format(col))\n",
    "        else:\n",
    "            print('{} \\t\\t: values are: {}'.format(col if len(col)>15 else col + \"\\t\\t\", val))\n",
    "df = df.rename(columns={'officer_years_of_service': 'officer_yos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(df['raw_EnforcementAction']):\n",
    "    print(n)\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "source": [
    "# Preprocess to compare search rates\n",
    "\n",
    "Calculate search rates for each officer race and each subject race across each county"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# General functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_race = ['black', 'hispanic']\n",
    "\n",
    "def remove_general_unused_columns(data, keep=[]):\n",
    "    columns_unused = ['officer_id_hash', 'vehicle_registration_state', 'type']\n",
    "    columns_reasons = ['reason_for_stop', 'reason_for_search', 'notes', 'violation', 'search_basis']\n",
    "    columns_raw = ['raw_EnforcementAction', 'raw_SearchType', 'raw_Ethnicity', 'raw_row_number_new', 'raw_Race', 'raw_row_number_old', 'raw_row_number']\n",
    "    columns_geography = ['location', 'date','time', 'department_name', 'unit']\n",
    "    general_columns_to_remove=columns_unused + columns_reasons + columns_raw + columns_geography\n",
    "    return data.drop(columns=[ x for x in general_columns_to_remove if x not in keep])\n",
    "\n",
    "def print_search_rate(data):\n",
    "    number_stops = data['search_conducted'].shape[0]\n",
    "    number_search_conducted = data[data['search_conducted'] == True].shape[0]\n",
    "    print('Data contains {} stops and {} of them ({}%) resulted in searches.'.format(number_stops, number_search_conducted, 100 * float(number_search_conducted)/number_stops))\n",
    "\n",
    "def preprocess_for_grouping(data):\n",
    "    data['search_rate'] = data['search_conducted']\n",
    "    data = data.astype({'search_rate': float})\n",
    "    data['count'] = 1 # to count occurences\n",
    "    return data\n",
    "\n",
    "def separate_data(data, categories):\n",
    "    df = {}\n",
    "    for exp in categories:\n",
    "        df[exp] = data.loc[exp]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_race(data, min_race, categories, threshold, what_to_plot, ax_limits=None):\n",
    "\n",
    "    fig, ax_arr = plt.subplots(1, len(categories)) # 2 graphs\n",
    "    figsize = (14,5)\n",
    "    fig.set_size_inches(figsize) # fig size\n",
    "    fig.suptitle(min_race.title() + \" people search rates among officers\".format(min_race))\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=3)\n",
    "    for i, off_feat in enumerate(categories):\n",
    "\n",
    "        data_ = data[off_feat]\n",
    "        df_white_sub, df_minority = data_.loc['white'], data_.loc[min_race] #separate data\n",
    "        df_white_sub.reset_index(inplace=True), df_minority.reset_index(inplace=True) #reset index\n",
    "        df_merged = pd.merge(df_white_sub, df_minority, on='county_name', suffixes=['_white', '_minority']) # merge both\n",
    "\n",
    "        # remove where there are too little datapoints\n",
    "        cond_minority = df_merged['count_minority'] >= threshold\n",
    "\n",
    "        y = df_merged[what_to_plot + '_minority'][cond_minority]*100\n",
    "        x = df_merged[what_to_plot + '_white'][cond_minority]*100 if what_to_plot == 'search_rate' else pd.Series([i for i in range(y.shape[0])])\n",
    "        s = df_merged['count_minority'][cond_minority]/100\n",
    "\n",
    "        ax_arr[i].scatter(x, y, s=s, c=\"None\", edgecolors='black', linewidth=0.4)\n",
    "        ax_arr[i].set_xlabel(\"White \" + what_to_plot + \" (%)\")\n",
    "        ax_arr[i].set_ylabel(min_race.title() + \" \"+ what_to_plot +\" (%)\")\n",
    "\n",
    "        #plot regression\n",
    "        a, b, r, p_value, std_err = linregress(x.repeat(s), y.repeat(s))\n",
    "        sns.regplot(x=x.repeat(s), y=y.repeat(s), ax=ax_arr[i], label='{:.1f}*x + {:.1f}, r={:.2f}'.format(a,b,r), scatter=False, truncate=False).legend(loc=\"best\")\n",
    "\n",
    "        ax_arr[i].set_title(off_feat.title() +' officers')\n",
    "\n",
    "        if ax_limits:\n",
    "            ax_arr[i].set_xlim((0,ax_limits['x']))\n",
    "            ax_arr[i].set_ylim((0,ax_limits['y']))\n",
    "\n",
    "        if what_to_plot == 'search_rate':\n",
    "            # draw dotted line\n",
    "            max_ = df_merged[what_to_plot + '_minority'][cond_minority].max()\n",
    "            line = np.arange(0, max_ * 100, max_)\n",
    "            ax_arr[i].plot(line, line, c='black', linestyle=(0,(5,5)), linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "        if ax_limits is None:\n",
    "            max_x = 1\n",
    "            max_y = 1\n",
    "            reg_line = np.array(((0,b), (1, a + b)))\n",
    "        else:\n",
    "            max_x = ax_limits['x']\n",
    "            max_y = ax_limits['y']\n",
    "            reg_line = np.array(((0, b), (max_x, a*max_x + b)))\n",
    "\n",
    "        \n",
    "        color = px.colors.qualitative.Plotly[i]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, \n",
    "            y=y, \n",
    "            mode='markers',\n",
    "            marker=dict(size=np.sqrt(s), opacity=0.5, color=color),\n",
    "            text='size:' + s.astype(str),\n",
    "            name=off_feat.title() +' officers',\n",
    "            ), \n",
    "            row=1, col=i+1\n",
    "            )\n",
    "\n",
    "        fig.add_shape(type=\"line\",\n",
    "            x0=line[0], y0=line[0], x1=line[-1], y1=line[-1],\n",
    "            line=dict(\n",
    "                color=\"Grey\",\n",
    "                width=1,\n",
    "                dash=\"dot\",\n",
    "            ), row=1, col=i+1,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=reg_line[:,0], y=reg_line[:,1],\n",
    "            mode='lines',\n",
    "            name='{:.1f}*x + {:.1f}, r={:.2f}'.format(a,b,r),\n",
    "            line=dict(\n",
    "                color=color,\n",
    "                width=2,\n",
    "                dash=\"solid\")\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=\"White \" + what_to_plot + \" (%)\", range=[0, max_x], row=1, col=i+1)\n",
    "        fig.update_yaxes(title_text=min_race.title() + \" \"+ what_to_plot +\" (%)\", range=[0, max_y], row=1, col=i+1)\n",
    "\n",
    "    fig.update_layout(autosize=True, width=figsize[0]*100*0.7, height=figsize[1]*100*0.8, title_text=min_race.title() + \" people search rates among officers\".format(min_race))\n",
    "    fig.write_html(\"file_.html\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_search_rates(data, categories, threshold=500, what_to_plot='search_rate', ax_limits=None):\n",
    "    for i, race in enumerate(minority_race):\n",
    "        plot_race(data, race, categories, threshold, what_to_plot, ax_limits[i] if ax_limits else None)\n",
    "\n",
    "\n",
    "def plot_one_search_rate(data, categories, threshold=500, what_to_plot='search_rate', ax_limits=None):\n",
    "    for i, race in enumerate(minority_race):\n",
    "        plot_race(data, race, categories, threshold, what_to_plot, ax_limits[i] if ax_limits else None)\n",
    "        break\n",
    "\n",
    "\n",
    "# # separate data\n",
    "# df_race_sep = separate_data(df_race_mixed, officer_race)\n",
    "# df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# # plot it \n",
    "# plot_search_rates(df_race_sep, officer_race, 100, what_to_plot='stop_rate')\n",
    "plot_one_search_rate(df_race_sep, officer_race, 2000, ax_limits=[ {'x': 1.5, 'y':4},{'x': 1.5, 'y':2.6}])"
   ]
  },
  {
   "source": [
    "# Race of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_race = remove_general_unused_columns(df_race)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_race = preprocess_for_grouping(df_race)\n",
    "\n",
    "\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all = df_race.groupby(['officer_race','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})\n",
    "df_race_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_race_all_s = df_race.groupby(['officer_race','county_name', 'subject_race']).agg({'count':'count', 'search_rate':'identity'})\n",
    "# df_race_all = df_race.groupby(['officer_race','county_name']).agg({'count':'count'})\n",
    "# df_race_mixed = copy(df_race_all_s)\n",
    "# df_race_mixed['tot'] = df_race_all['count']\n",
    "# df_race_mixed['stop_rate'] = df_race_mixed['count'] / df_race_mixed['tot']\n",
    "# df_race_mixed.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_race_sep = separate_data(df_race_all, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_race_sep, officer_race, 2000)"
   ]
  },
  {
   "source": [
    "# Experience of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_experience_level = ['young', 'experienced', 'old']\n",
    "thresholds_experience = [2, 9]"
   ]
  },
  {
   "source": [
    "Preprocess the data to have what is needed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yos = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_yos = remove_general_unused_columns(df_yos)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_yos', 'search_conducted']\n",
    "df_yos.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_yos)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_yos = preprocess_for_grouping(df_yos)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_yos['age_category'] = df_yos['officer_yos'].apply(lambda x : officer_experience_level[0] if x < thresholds_experience[0] else (officer_experience_level[1] if x < thresholds_experience[1] else officer_experience_level[2]))\n",
    "df_yos_all = df_yos.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_yos_sep = separate_data(df_yos_all, officer_experience_level)\n",
    "df_yos_sep[officer_experience_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_yos_sep, officer_experience_level, 3000, ax_limits=[ {'x': 1.5, 'y':5},{'x': 1.5, 'y':2.6}]) #"
   ]
  },
  {
   "source": [
    "# Age of the officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_age_level = ['young', 'experienced', 'old']\n",
    "thresholds_age = [32, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_age = remove_general_unused_columns(df_age)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_age', 'search_conducted']\n",
    "df_age.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_age.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_age)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_age = preprocess_for_grouping(df_age)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_age['age_category'] = df_age['officer_age'].apply(lambda x : officer_age_level[0] if x < thresholds_age[0] else (officer_age_level[1] if x < thresholds_age[1] else officer_age_level[2]))\n",
    "df_age_all = df_age.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_age_sep = separate_data(df_age_all, officer_age_level)\n",
    "df_age_sep[officer_age_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_age_sep, officer_age_level, 3000, ax_limits=[{'x': 2, 'y':4},{'x': 2, 'y':3}])"
   ]
  },
  {
   "source": [
    "# Gender of the officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_sex = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sex = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_sex = remove_general_unused_columns(df_sex)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_sex', 'search_conducted']\n",
    "df_sex.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_sex.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_sex)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_sex = preprocess_for_grouping(df_sex)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "# df_gender['age_category'] = df_gender['officer_gender'].apply(lambda x : officer_age_level[0] if x < thresholds_age[0] else (officer_age_level[1] if x < thresholds_age[1] else officer_age_level[2]))\n",
    "df_sex_all = df_sex.groupby(['officer_sex','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_sex_sep = separate_data(df_sex_all, officer_sex)\n",
    "\n",
    "avg_female = df_sex_sep['female']['search_rate'].mean()\n",
    "avg_male = df_sex_sep['male']['search_rate'].mean()\n",
    "\n",
    "df_sex_sep['female']['search_rate'] = df_sex_sep['female']['search_rate'].apply(lambda x : (avg_male/avg_female)*x)\n",
    "# df_sex_sep[officer_age_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_sex_sep, officer_sex, 500)#, ax_limits=[{'x': 1.25, 'y':3.5},{'x': 2, 'y':3}])"
   ]
  },
  {
   "source": [
    "# Importance of characteristics of officer for stop_rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Race of the officer (with stop_rate)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = copy(df)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "df_race = preprocess_for_grouping(df_race)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all_s = df_race.groupby(['officer_race','county_name', 'subject_race']).agg({'count':'count'})\n",
    "df_race_all = df_race.groupby(['officer_race','county_name']).agg({'count':'count'})\n",
    "\n",
    "df_race_mixed = copy(df_race_all_s)\n",
    "df_race_mixed['tot'] = df_race_all['count']\n",
    "df_race_mixed['stop_rate'] = df_race_mixed['count'] / df_race_mixed['tot']\n",
    "\n",
    "\n",
    "df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "df_race_mixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = separate_data( df_race_mixed, ['white'])['white']\n",
    "df.reset_index(level=[0,1], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.subject_race == 'black']['count'].sum())\n",
    "print(df['count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_race_stop(data, min_race, categories, threshold):\n",
    "\n",
    "    what_to_plot = 'stop_rate'\n",
    "\n",
    "    fig, ax_arr = plt.subplots(1, 3) # 2 graphs\n",
    "    fig.set_size_inches(17,5) # fig size\n",
    "    fig.suptitle(min_race.title() + \" people \"+ what_to_plot+\" among officers\".format(min_race))\n",
    "\n",
    "    for i, off_feat in enumerate(categories):\n",
    "\n",
    "        data_ = data[off_feat]\n",
    "        df_white_sub, df_minority = data_.loc['white'], data_.loc[min_race] #separate data\n",
    "        df_white_sub.reset_index(inplace=True), df_minority.reset_index(inplace=True) #reset index\n",
    "        df_merged = pd.merge(df_white_sub, df_minority, on='county_name', suffixes=['_white', '_minority']) # merge both\n",
    "\n",
    "        # remove where there are too little datapoints\n",
    "        cond_minority = df_merged['count_minority'] >= threshold\n",
    "\n",
    "        y = df_merged[what_to_plot + '_minority'][cond_minority]*100\n",
    "        total =  float(df_merged['count_minority'].sum())\n",
    "        print(total)\n",
    "        s = df_merged['count_minority'][cond_minority] #.apply(lambda x: x / total)\n",
    "\n",
    "        sns.histplot(y.repeat(s), ax=ax_arr[i], bins=8, kde=True)\n",
    "\n",
    "\n",
    "        ax_arr[i].set_xlabel(min_race.title() + what_to_plot + \" (%)\")\n",
    "        ax_arr[i].set_ylabel(\"Number of \" + min_race +\" stops\")\n",
    "\n",
    "\n",
    "        ax_arr[i].set_title(off_feat.title() +' officers')\n",
    "\n",
    "\n",
    "\n",
    "def plot_stop_rates(data, categories, threshold= 0):\n",
    "    for race in minority_race + ['white']:\n",
    "        plot_race_stop(data, race, categories, threshold)\n",
    "\n",
    "\n",
    "# separate data\n",
    "df_race_sep = separate_data(df_race_mixed, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot it \n",
    "plot_stop_rates(df_race_sep, officer_race, 0)"
   ]
  },
  {
   "source": [
    "# Veil of darkness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_CHARACTERISTIC = 'officer_race'\n",
    "\n",
    "df_veil = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "df_veil = remove_general_unused_columns(df_veil, columns_time)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC , 'search_conducted']\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "df_veil['date'] = pd.to_datetime(df_veil['date'])\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "starts = []\n",
    "ends = []\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015]\n",
    "\n",
    "for y in years:\n",
    "    starts.append(datetime.datetime.strptime(f\"01-10-{y}\", \"%d-%m-%Y\"))\n",
    "    ends.append(datetime.datetime.strptime(f\"30-10-{y}\", \"%d-%m-%Y\"))\n",
    "\n",
    "\n",
    "df_veil['month'] = df_veil['date'].apply(lambda x : np.sum([s <= x <= e for s,e in zip(starts, ends)]) > 0 )\n",
    "df_veil = df_veil[df_veil['month']]\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veiled = copy(df_veil)\n",
    "hours = [ f'{x}:' for x in range(17, 21)]\n",
    "\n",
    "df_veiled['time_bool'] = df_veiled['time'].apply(lambda x: x[0:3] in hours) \n",
    "df_veiled_both = df_veiled[ df_veiled['time_bool']]\n",
    "print(df_veiled_both.shape)\n",
    "\n",
    "df_veiled_both['time_period'] = df_veiled_both['time'].apply(lambda x : x[0:4])\n",
    "df_veiled_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_veiled_both['count'] = 1\n",
    "\n",
    "# df_veil_of_darkness = df_veiled_both.groupby(['officer_race','time_period','subject_race']).agg({'count':'count'})\n",
    "# df_veil_of_darkness_all = df_veiled_both.groupby(['officer_race','time_period']).agg({'count':'count'})\n",
    "\n",
    "# df_veil_of_darkness['tot'] = df_veil_of_darkness_all['count']\n",
    "# df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count'] / df_veil_of_darkness['tot']\n",
    "\n",
    "\n",
    "# # df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "# df_veil_of_darkness = df_veil_of_darkness.reset_index()\n",
    "\n",
    "# df_veil_of_darkness.head()\n",
    "\n",
    "\n",
    "# # df_veil_white = separate_data(df_veil_of_darkness, officer_race)\n",
    "# # df_veil_white['white'].head(10)\n",
    "\n",
    "df_veiled_both['count'] = 1\n",
    "\n",
    "df_veil_of_darkness = df_veiled_both.groupby(['time_period','subject_race']).agg({'count':'count'})\n",
    "df_veil_of_darkness_all = df_veiled_both.groupby('time_period').agg({'count':'count'})\n",
    "\n",
    "df_veil_of_darkness.reset_index(inplace=True)\n",
    "df_veil_of_darkness_all.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_veil_of_darkness['tot'] = df_veil_of_darkness_all['count']\n",
    "# df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count'] / df_veil_of_darkness['tot']\n",
    "\n",
    "\n",
    "# df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "# df_veil_of_darkness = df_veil_of_darkness.reset_index()\n",
    "\n",
    "df_veil_of_darkness = df_veil_of_darkness.merge(df_veil_of_darkness_all, on=['time_period'])\n",
    "df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count_x'] / df_veil_of_darkness['count_y']\n",
    "\n",
    "df_veil_of_darkness = df_veil_of_darkness[df_veil_of_darkness['subject_race'] == 'black']\n",
    "\n",
    "df_veil_of_darkness.head()\n",
    "\n",
    "# df_veil_white = separate_data(df_veil_of_darkness, officer_race)\n",
    "# df_veil_white['white'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veil_study = df_veil_of_darkness.reset_index()\n",
    "# df_veil_study = df_veil_white['white'].reset_index()\n",
    "df_veil_study['before_sunset'] = df_veil_study['time_period'].apply(lambda x: x < '20:1')\n",
    "df_veil_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = []\n",
    "for i in range(17, 21):\n",
    "    for j in range(0, 60, 10):\n",
    "        periods.append(f\"{i}:{int(j/10)}\")\n",
    "print(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10,5))\n",
    "\n",
    "data_black = df_veil_study[ df_veil_study['subject_race'] == 'black']\n",
    "\n",
    "sns.lineplot(x='time_period', y='black_stop_rate', data=data_black)\n",
    "plt.axvline('19:1', c='black', linestyle='dashed')\n",
    "\n",
    "data_black['before_sunset'] = data_black['time_period'].apply(lambda x : x < '19:1')\n",
    "\n",
    "data_black['time_period_v'] = data_black['time_period'].apply(lambda x : periods.index(x))\n",
    "\n",
    "data_black_before = data_black[data_black['before_sunset']]\n",
    "data_black_after = data_black[data_black['before_sunset'] == False]\n",
    "\n",
    "data_black_before.head()\n",
    "\n",
    "sns.regplot(x='time_period_v', y='black_stop_rate', data=data_black_before)\n",
    "sns.regplot(x='time_period_v', y='black_stop_rate', data=data_black_after)\n",
    "# sns.regplot(x=data_black_after['time_period'], y=data_black_after['black_stop_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# def plot_veil_of_darkness(data, period= ['01-12', '20-12'], sunset_time='17:3', hour_range=[15,20]):\n",
    "\n",
    "\n",
    "\n",
    "period= ['05-06', '28-07']\n",
    "sunset_time='20:1'\n",
    "hour_range=[18,22]\n",
    "\n",
    "\n",
    "df_veil = copy(data)\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "df_veil = remove_general_unused_columns(df_veil, columns_time)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC , 'search_conducted']\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "df_veil['date'] = pd.to_datetime(df_veil['date'])\n",
    "\n",
    "\n",
    "# select range of the period\n",
    "starts = []\n",
    "ends = []\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015]\n",
    "for y in years:\n",
    "    starts.append(datetime.datetime.strptime(f\"{period[0]}-{y}\", \"%d-%m-%Y\"))\n",
    "    ends.append(datetime.datetime.strptime(f\"{period[1]}-{y}\", \"%d-%m-%Y\"))\n",
    "\n",
    "df_veil['month'] = df_veil['date'].apply(lambda x : np.sum([s <= x <= e for s,e in zip(starts, ends)]) > 0 )\n",
    "df_veil = df_veil[df_veil['month']]\n",
    "\n",
    "# select hour range\n",
    "hours = [ f'{x}:' for x in range(hour_range[0], hour_range[1])]\n",
    "df_veiled['time_bool'] = df_veiled['time'].apply(lambda x: x[0:3] in hours) \n",
    "df_veiled_both = df_veiled[ df_veiled['time_bool']]\n",
    "df_veiled_both['time_period'] = df_veiled_both['time'].apply(lambda x : x[0:4])\n",
    "\n",
    "# group \n",
    "df_veiled_both['count'] = 1\n",
    "df_veil_of_darkness = df_veiled_both.groupby(['time_period','subject_race']).agg({'count':'count'})\n",
    "df_veil_of_darkness_all = df_veiled_both.groupby('time_period').agg({'count':'count'})\n",
    "df_veil_of_darkness.reset_index(inplace=True)\n",
    "df_veil_of_darkness_all.reset_index(inplace=True)\n",
    "df_veil_of_darkness = df_veil_of_darkness.merge(df_veil_of_darkness_all, on=['time_period'])\n",
    "df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count_x'] / df_veil_of_darkness['count_y']\n",
    "df_veil_of_darkness = df_veil_of_darkness[df_veil_of_darkness['subject_race'] == 'black']\n",
    "df_veil_study = df_veil_of_darkness.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# select only black people arrested\n",
    "data_black = df_veil_study[df_veil_study['subject_race'] == 'black']\n",
    "\n",
    "\n",
    "return data_black\n",
    "\n",
    "\n",
    "\n",
    "# df_black = plot_veil_of_darkness(df, period = period, sunset_time = sunset_time, hour_range = hour_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall astral\n",
    "# !pip install astral==1.10.1\n",
    "# !pip install astral\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm.notebook import tqdm, tqdm_notebook\n",
    "from datetime import datetime\n",
    "tqdm_notebook().pandas()\n",
    "# s = sun(cityobserver, date=datetime.date())\n",
    "\n",
    "# def plot_veil_of_darkness(data, period= ['01-12', '20-12'], sunset_time='17:3', hour_range=[15,20]):\n",
    "CHOSEN_CHARACTERISTIC = 'officer_race'\n",
    "\n",
    "\n",
    "df_veil = copy(df)\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "columns_to_drop = ['subject_sex', 'officer_age', 'subject_age', 'arrest_made', 'officer_yos', 'officer_sex', 'officer_yos', 'citation_issued', 'warning_issued', 'outcome', 'frisk_performed', 'search_conducted']\n",
    "df_veil = remove_general_unused_columns(df_veil, columns_time)\n",
    "df_veil.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC ]\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_veil.shape[0]))\n",
    "\n",
    "df_veil['date'] = (df_veil['date'] + ' ' + df_veil['time']).progress_apply(lambda x : datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_veil.drop(columns=['time'], inplace=True)\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astral.sun as astralsun\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "from datetime import datetime\n",
    "\n",
    "city = LocationInfo(\"Orlando\")\n",
    "\n",
    "df_veil['dusk_time'] = df_veil['date'].progress_apply(lambda x : sun(city.observer, date=x)['dusk'].replace(tzinfo=None))\n",
    "df_veil['time_relative'] = df_veil['date'] - df_veil['dusk_time'] #.progress_apply(lambda x : x - )\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 20\n",
    "EXTEND= 2\n",
    "\n",
    "categories = [timedelta(minutes=15*i) for i in range(-WIDTH-EXTEND, WIDTH+1)]\n",
    "\n",
    "def get_category(timed):\n",
    "    for i, t in enumerate(categories):\n",
    "        if timed < t:\n",
    "            return i-WIDTH-EXTEND-1 if i else -1\n",
    "    return -1\n",
    "# print(categories)\n",
    "df_veil['time_cat'] = df_veil['time_relative'].progress_apply(lambda x : get_category(x))\n",
    "df_veil_cleaned = df_veil[df_veil['time_cat'] != -1]\n",
    "df_veil_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the county\n",
    "df_for_vod = copy(df_veil_cleaned)\n",
    "\n",
    "# start_h = datetime.time(19,0,0)\n",
    "# start_h = datetime.time(19,0,0)\n",
    "\n",
    "# df_for_vod['hour_dusk'] = df_for_vod['date'].progress_apply(lambda x : x.strftime('%H:%M'))\n",
    "\n",
    "# df_for_vod['chosen_dusk'] = df_for_vod['hour_dusk'].progress_apply(lambda x: )\n",
    "\n",
    "# df_for_vod = df_for_vod[df_for_vod['hour_dusk']]\n",
    "df_for_vod.head()\n",
    "\n",
    "# df_vod = df_vod[df_vod['county_name'].isin([])]\n",
    "# df_vod = df_vod[df_vod['officer_race'] == 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_vod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_vod = df_for_vod[df_for_vod['county_name'] == 'Holmes County']\n",
    "print(df_for_vod.shape[0])\n",
    "df_for_vod.head()\n",
    "\n",
    "\n",
    "#    Working : Taylor county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df_to_group, which_hour=None):\n",
    "    df_to_group['count'] = 1\n",
    "\n",
    "    if which_hour:\n",
    "        df_to_group = df_to_group[]\n",
    "\n",
    "    # group the categories\n",
    "    df_vod = df_to_group.groupby(['time_cat','subject_race']).agg({'count':'count'})\n",
    "    df_grouped_by_timecat = df_to_group.groupby('time_cat').agg({'count':'count'})\n",
    "\n",
    "    # merge both\n",
    "    df_vod.reset_index(inplace=True)\n",
    "    df_grouped_by_timecat.reset_index(inplace=True)\n",
    "    df_vod = df_vod.merge(df_grouped_by_timecat, on=['time_cat'])\n",
    "\n",
    "    # compute the stop_rate\n",
    "    df_vod['race_stop_rate'] = df_vod['count_x'] / df_vod['count_y']\n",
    "    return df_vod\n",
    "\n",
    "\n",
    "df_vod = group_data(df_for_vod)\n",
    "df_vod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only black people arrested\n",
    "data_black = df_vod[df_vod['subject_race'] == 'black']\n",
    "data_black.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_veil_cleaned['county_name']:\n",
    "    if 'llier' in c:\n",
    "        print(c)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data_o, time_range=[-8,7]):\n",
    "    data = copy(data_o)\n",
    "    data = data[data['time_cat'].isin(range(time_range[0],time_range[1]))]\n",
    "    data = data[~data['time_cat'].isin(range(-1,0))]\n",
    "\n",
    "    data['time_cat'] = data['time_cat'] * 10\n",
    "    data['race_stop_rate'] = data['race_stop_rate'] * 100\n",
    "\n",
    "    # plot points\n",
    "    figure(figsize=(10,5))\n",
    "    ax = sns.scatterplot(x='time_cat', y='race_stop_rate', size='count_y', sizes=(20,200) ,data=data, color='black')\n",
    "    plt.axvline(0, c='black', linestyle='dashed')\n",
    "\n",
    "    # two different regressions\n",
    "    data_before = data[data['time_cat'] < -1]\n",
    "    data_after = data[data['time_cat'] > -1]\n",
    "\n",
    "    # # plot regressions\n",
    "    # sns.regplot(x='time_cat', y='race_stop_rate', data=data_before, scatter=False)\n",
    "    # sns.regplot(x='time_cat', y='race_stop_rate', data=data_after, scatter=False)\n",
    "    before_average = data_before['race_stop_rate'].mean()\n",
    "    after_average = data_after['race_stop_rate'].mean()\n",
    "\n",
    "    plt.hlines(before_average, -80, -20)\n",
    "    plt.hlines(after_average, 0, 60)\n",
    "\n",
    "    ax.set_xlabel('Time since dusk (min)')\n",
    "    ax.set_ylabel('Percentage of stopped drivers who are black')\n",
    "\n",
    "\n",
    "\n",
    "def plot_one_county(county_name):\n",
    "    df_for_vod = copy(df_veil_cleaned)\n",
    "    df_for_vod = df_for_vod[df_for_vod['county_name'] == county_name]\n",
    "    for race in ['white', 'black', 'hispanic']:\n",
    "        df_ = group_data(df_for_vod[df_for_vod['officer_race'] == race])\n",
    "        plot(df_[df_['subject_race'] == 'black'])\n",
    "\n",
    "\n",
    "plot_one_county('Santa Rosa County')\n",
    "# plot(df_vod[df_vod['subject_race'] == 'black'])\n",
    "\n",
    "# plot(df_vod[df_vod['subject_race'] == 'black'])\n",
    "# plot(df_vod[df_vod['subject_race'] == 'white'])\n",
    "# plot(df_vod[df_vod['subject_race'] == 'hispanic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preprocess for grouping\n",
    "data['search_rate'] = data['search_conducted']\n",
    "data = data.astype({'search_rate': float})\n",
    "data['count'] = 1 # to count occurences\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_yos['age_category'] = df_yos['officer_yos'].apply(lambda x : officer_experience_level[0] if x < thresholds_experience[0] else (officer_experience_level[1] if x < thresholds_experience[1] else officer_experience_level[2]))\n",
    "df_yos_all = df_yos.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Logistic regression of characteristics of officers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_raw = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_log_raw = remove_general_unused_columns(df_log_raw)\n",
    "df_log_raw.drop(columns=['arrest_made', 'citation_issued','warning_issued', 'outcome', 'frisk_performed'], inplace=True)\n",
    "df_log_raw.dropna(inplace=True, subset=['search_conducted'])\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_age', 'officer_yos', 'officer_age']\n",
    "for feat in important_features:\n",
    "    m = df_log_raw[feat].mean()\n",
    "    df_log_raw[feat] = df_log_raw[feat].fillna((m))\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_log_raw.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_log_raw)\n",
    "\n",
    "df_log_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for regression\n",
    "df_log = copy(df_log_raw)\n",
    "\n",
    "print('Processing sub races')\n",
    "sub_races = list(df_log['subject_race'].unique())\n",
    "for race in sub_races:\n",
    "    df_log['subject_' + (race if isinstance(race, str) else 'nan')] = (df_log['subject_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off races')\n",
    "off_races = list(df_log['officer_race'].unique())\n",
    "for race in off_races:\n",
    "    df_log['officer_' + (race if isinstance(race, str) else 'nan')] = (df_log['officer_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing sub genders')\n",
    "sub_genders = list(df_log['subject_sex'].unique())\n",
    "for gender in sub_genders:\n",
    "    df_log['subject_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['subject_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off genders')\n",
    "off_genders = list(df_log['officer_sex'].unique())\n",
    "for gender in off_genders:\n",
    "    df_log['officer_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['officer_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off yos')\n",
    "cat_exp = [0, 2, 6, 10, 15, 100]\n",
    "for infi in range(len(cat_exp) -1):\n",
    "    df_log['officer_exp_' + str(cat_exp[infi]) ] = ( df_log['officer_yos'].between(cat_exp[infi],cat_exp[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off age')\n",
    "cat_age = [15, 25, 35, 45, 55, 70, 100]\n",
    "for infi in range(len(cat_age) -1):\n",
    "    df_log['officer_age_' + str(cat_age[infi]) ] = ( df_log['officer_age'].between(cat_age[infi],cat_age[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "\n",
    "print('Processing search')\n",
    "df_log['search_conducted'] = df_log['search_conducted'].apply(lambda x : int(x))\n",
    "\n",
    "print('Removing old columns')\n",
    "df_log.drop(columns=['subject_race', 'officer_race', 'subject_sex', 'officer_sex', 'officer_yos', 'officer_age'], inplace=True)\n",
    "\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = df_log['county_name'].unique()\n",
    "maxi = 0\n",
    "maxi_c = 0\n",
    "for c in counties:\n",
    "    v = df_log[df_log['county_name'] == c].shape[0]\n",
    "    if v > maxi:\n",
    "        maxi = v\n",
    "        maxi_c = c\n",
    "\n",
    "print(maxi_c, maxi )\n",
    "\n",
    "df_log = df_log[df_log['county_name'] == maxi_c].drop(columns='county_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_log['search_conducted'].to_numpy()\n",
    "x = df_log.drop(columns='search_conducted').to_numpy()\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x, y)\n",
    "params = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters of logistic regression are:\")\n",
    "for i, col in enumerate(df_log.drop(columns='search_conducted').columns):\n",
    "    print(\" - {} : {:.3f} \".format(col,params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance, DMatrix\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model).set_yticklabels(df_log.drop(columns='search_conducted').columns[:23])"
   ]
  },
  {
   "source": [
    "We see that experienced officers do not search often people. This may be due because they are at a higher level, so they do not do the search themselves. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Old stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_officer_race(data, race):\n",
    "    data_ = data[race]\n",
    "    df_white_sub, df_black_sub, df_hispanic = data_.loc['white'], data_.loc['black'], data_.loc['hispanic'] #separate data\n",
    "    df_white_sub.reset_index(inplace=True), df_black_sub.reset_index(inplace=True), df_hispanic.reset_index(inplace=True) #reset index\n",
    "    df_merged = pd.merge(df_white_sub, df_black_sub, on='county_name', suffixes=['', '_black'])\n",
    "    df_merged = pd.merge(df_merged, df_hispanic, on='county_name', suffixes=['_white', '_hispanic'])\n",
    "    fig, ax_arr = plt.subplots(1, 2) # 2 graphs\n",
    "    fig.set_size_inches(9,5) # fig size\n",
    "\n",
    "    fig.suptitle(\"Minorities search rates of {} officers\".format(race))\n",
    "\n",
    "    ax_arr[0].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_black']*100)\n",
    "    ax_arr[0].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[0].set_ylabel(\"Black search rate (%)\")\n",
    "\n",
    "    ax_arr[1].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_hispanic']*100)\n",
    "    ax_arr[1].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[1].set_ylabel(\"Black search rate (%)\")\n",
    "    \n",
    "\n",
    "for race in officer_race:\n",
    "    plot_officer_race(df_officers, race)"
   ]
  }
 ]
}