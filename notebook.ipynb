{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "03c4f2befd112ae6133593a618d4cc9f49a940019336ec3e14700801b49563e8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import copy\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "state = 'fl_statewide_2020_04_01.zip'\n",
    "state2 = 'ca_long_beach_2020_04_01.csv'"
   ]
  },
  {
   "source": [
    "# Preprocessing whole dataset (do not execute if working on full data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(folder + state)\n",
    "print(df_full.columns)"
   ]
  },
  {
   "source": [
    "Reducing the amount of data for experimentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_file_path = folder + state.split('.')[0] + \"_cut.csv\"\n",
    "total_size = df_full.shape[0]\n",
    "df = df_full.sample(n=int(total_size/100))\n",
    "print(\"Full dataset of size {} was reduced to subset of {} elements.\".format(total_size, df.shape[0]))\n",
    "df.to_csv(cut_file_path, index = False)"
   ]
  },
  {
   "source": [
    "# Load the data (currently loading all data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df =  pd.read_csv(folder + state)\n",
    "print(\"Dataset is composed of {} stops. Columns are: \\n\".format(df.shape[0]))\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] != np.float64:\n",
    "        val = df[col].unique()\n",
    "        if len(val) > 20:\n",
    "            print('{} \\t\\t: too much different values'.format(col))\n",
    "        else:\n",
    "            print('{} \\t\\t: values are: {}'.format(col if len(col)>15 else col + \"\\t\\t\", val))\n",
    "df = df.rename(columns={'officer_years_of_service': 'officer_yos'})"
   ]
  },
  {
   "source": [
    "# Preprocess to compare search rates\n",
    "\n",
    "Calculate search rates for each officer race and each subject race across each county"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# General functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_race = ['black', 'hispanic']\n",
    "\n",
    "def remove_general_unused_columns(data):\n",
    "    columns_unused = ['officer_id_hash', 'vehicle_registration_state', 'type']\n",
    "    columns_reasons = ['reason_for_stop', 'reason_for_search', 'notes', 'violation', 'search_basis']\n",
    "    columns_raw = ['raw_EnforcementAction', 'raw_SearchType', 'raw_Ethnicity', 'raw_row_number_new', 'raw_Race', 'raw_row_number_old', 'raw_row_number']\n",
    "    columns_geography = ['location', 'department_name', 'unit']\n",
    "    return data.drop(columns=columns_unused + columns_reasons + columns_raw + columns_geography)\n",
    "\n",
    "def print_search_rate(data):\n",
    "    number_stops = data['search_conducted'].shape[0]\n",
    "    number_search_conducted = data[data['search_conducted'] == True].shape[0]\n",
    "    print('Data contains {} stops and {} of them ({}%) resulted in searches.'.format(number_stops, number_search_conducted, 100 * float(number_search_conducted)/number_stops))\n",
    "\n",
    "def preprocess_for_grouping(data):\n",
    "    data['search_rate'] = data['search_conducted']\n",
    "    data = data.astype({'search_rate': float})\n",
    "    data['count'] = 1 # to count occurences\n",
    "    return data\n",
    "\n",
    "def separate_data(data, categories):\n",
    "    df = {}\n",
    "    for exp in categories:\n",
    "        df[exp] = data.loc[exp]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_race(data, min_race, categories, threshold, what_to_plot, ax_limits=None, filename='test.html'):\n",
    "\n",
    "    fig, ax_arr = plt.subplots(1, 3) # 2 graphs\n",
    "    figsize = (14,5)\n",
    "    fig.set_size_inches(14,5) # fig size\n",
    "    fig.suptitle(min_race.title() + \" people search rates among officers\".format(min_race))\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=3)\n",
    "    for i, off_feat in enumerate(categories):\n",
    "        filename = off_feat + '_' + filename\n",
    "\n",
    "        data_ = data[off_feat]\n",
    "        df_white_sub, df_minority = data_.loc['white'], data_.loc[min_race] #separate data\n",
    "        df_white_sub.reset_index(inplace=True), df_minority.reset_index(inplace=True) #reset index\n",
    "        df_merged = pd.merge(df_white_sub, df_minority, on='county_name', suffixes=['_white', '_minority']) # merge both\n",
    "\n",
    "        # remove where there are too little datapoints\n",
    "        cond_minority = df_merged['count_minority'] >= threshold\n",
    "\n",
    "        x = df_merged[what_to_plot + '_white'][cond_minority]*100\n",
    "        y = df_merged[what_to_plot + '_minority'][cond_minority]*100\n",
    "        s = df_merged['count_minority'][cond_minority]/100\n",
    "\n",
    "        ax_arr[i].scatter(x, y, s=s, c=\"None\", edgecolors='black', linewidth=0.4)\n",
    "        ax_arr[i].set_xlabel(\"White \" + what_to_plot + \" (%)\")\n",
    "        ax_arr[i].set_ylabel(min_race.title() + \" \"+ what_to_plot +\" (%)\")\n",
    "\n",
    "        #plot regression\n",
    "        a, b, r, p_value, std_err = linregress(x.repeat(s), y.repeat(s))\n",
    "        sns.regplot(x=x.repeat(s), y=y.repeat(s), ax=ax_arr[i], label='{:.1f}*x + {:.1f}, r={:.2f}'.format(a,b,r), scatter=False, truncate=False).legend(loc=\"best\")\n",
    "\n",
    "        ax_arr[i].set_title(off_feat.title() +' officers')\n",
    "\n",
    "        if what_to_plot == 'search_rate':\n",
    "            # draw dotted line\n",
    "            max_ = df_merged[what_to_plot + '_minority'][cond_minority].max()\n",
    "            line = np.arange(0, max_ * 100, max_)\n",
    "            ax_arr[i].plot(line, line, c='black', linestyle=(0,(5,5)), linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "        if ax_limits is None:\n",
    "            max_x = 1\n",
    "            max_y = 1\n",
    "            reg_line = np.array(((0,b), (1, a + b)))\n",
    "        else:\n",
    "            max_x = ax_limits['x']\n",
    "            max_y = ax_limits['y']\n",
    "            reg_line = np.array(((0, b), (max_x, a*max_x + b)))\n",
    "\n",
    "        \n",
    "        color = px.colors.qualitative.Plotly[i]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, \n",
    "            y=y, \n",
    "            mode='markers',\n",
    "            marker=dict(size=np.sqrt(s), opacity=0.5, color=color),\n",
    "            text='size:' + s.astype(str),\n",
    "            name=off_feat.title() +' officers',\n",
    "            ), \n",
    "            row=1, col=i+1\n",
    "            )\n",
    "\n",
    "        fig.add_shape(type=\"line\",\n",
    "            x0=line[0], y0=line[0], x1=line[-1], y1=line[-1],\n",
    "            line=dict(\n",
    "                color=\"Grey\",\n",
    "                width=1,\n",
    "                dash=\"dot\",\n",
    "            ), row=1, col=i+1,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=reg_line[:,0], y=reg_line[:,1],\n",
    "            mode='lines',\n",
    "            name='{:.1f}*x + {:.1f}, r={:.2f}'.format(a,b,r),\n",
    "            line=dict(\n",
    "                color=color,\n",
    "                width=2,\n",
    "                dash=\"solid\")\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=\"White \" + what_to_plot + \" (%)\", range=[0, max_x], row=1, col=i+1)\n",
    "        fig.update_yaxes(title_text=min_race.title() + \" \"+ what_to_plot +\" (%)\", range=[0, max_y], row=1, col=i+1)\n",
    "\n",
    "    fig.update_layout(autosize=True, width=figsize[0]*100*0.7, height=figsize[1]*100*0.8, title_text=min_race.title() + \" people search rates among officers\".format(min_race))\n",
    "    fig.write_html(filename)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_search_rates(data, categories, threshold=500, what_to_plot='search_rate', ax_limits=None, filename='test.html'):\n",
    "    for i, race in enumerate(minority_race):\n",
    "        filename=race + '_' + filename\n",
    "        plot_race(data, race, categories, threshold, what_to_plot, ax_limits[i] if ax_limits else None, filename=filename)\n",
    "\n",
    "\n",
    "def plot_one_search_rate(data, categories, threshold=500, what_to_plot='search_rate', ax_limits=None):\n",
    "    for i, race in enumerate(minority_race):\n",
    "        plot_race(data, race, categories, threshold, what_to_plot, ax_limits[i] if ax_limits else None)\n",
    "        break\n",
    "\n",
    "\n",
    "# # separate data\n",
    "# df_race_sep = separate_data(df_race_mixed, officer_race)\n",
    "# df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# # plot it \n",
    "# plot_search_rates(df_race_sep, officer_race, 100, what_to_plot='stop_rate')"
   ]
  },
  {
   "source": [
    "# Race of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_race = remove_general_unused_columns(df_race)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_race = preprocess_for_grouping(df_race)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all = df_race.groupby(['officer_race','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_race_sep = separate_data(df_race_all, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "ax_limits = [\n",
    "    {'x':2, 'y':4},\n",
    "    {'x':2, 'y':4},\n",
    "]\n",
    "plot_search_rates(df_race_sep, officer_race, 3000, filename='search_rate.html', ax_limits=ax_limits )"
   ]
  },
  {
   "source": [
    "# Experience of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_experience_level = ['young', 'experienced', 'old']\n",
    "thresholds_experience = [2, 9]"
   ]
  },
  {
   "source": [
    "Preprocess the data to have what is needed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yos = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_yos = remove_general_unused_columns(df_yos)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_yos', 'search_conducted']\n",
    "df_yos.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_yos)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_yos = preprocess_for_grouping(df_yos)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_yos['age_category'] = df_yos['officer_yos'].apply(lambda x : officer_experience_level[0] if x < thresholds_experience[0] else (officer_experience_level[1] if x < thresholds_experience[1] else officer_experience_level[2]))\n",
    "df_yos_all = df_yos.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_yos_sep = separate_data(df_yos_all, officer_experience_level)\n",
    "df_yos_sep[officer_experience_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_yos_sep, officer_experience_level, 5000)"
   ]
  },
  {
   "source": [
    "# Age of the officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_age_level = ['young', 'experienced', 'old']\n",
    "thresholds_age = [30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_age = remove_general_unused_columns(df_age)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_age', 'search_conducted']\n",
    "df_age.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_age.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_age)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_age = preprocess_for_grouping(df_age)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_age['age_category'] = df_age['officer_age'].apply(lambda x : officer_age_level[0] if x < thresholds_age[0] else (officer_age_level[1] if x < thresholds_age[1] else officer_age_level[2]))\n",
    "df_age_all = df_age.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_age_sep = separate_data(df_age_all, officer_age_level)\n",
    "df_age_sep[officer_age_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_age_sep, officer_age_level, 1000, ax_limits=[{'x': 1.5, 'y':3},{'x': 2, 'y':3}])"
   ]
  },
  {
   "source": [
    "# Race of the officer (with stop_rate)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all_s = df_race.groupby(['officer_race','county_name', 'subject_race']).agg({'count':'count'})\n",
    "df_race_all = df_race.groupby(['officer_race','county_name']).agg({'count':'count'})\n",
    "\n",
    "df_race_mixed = copy(df_race_all_s)\n",
    "df_race_mixed['tot'] = df_race_all['count']\n",
    "df_race_mixed['stop_rate'] = df_race_mixed['count'] / df_race_mixed['tot']\n",
    "\n",
    "df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "# df_race_mixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_race_sep = separate_data(df_race_mixed, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_race_sep, officer_race, 100, what_to_plot='stop_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Logistic regression of characteristics of officers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = copy(df)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "df_race = preprocess_for_grouping(df_race)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all_s = df_race.groupby(['officer_race','county_name', 'subject_race']).agg({'count':'count'})\n",
    "df_race_all = df_race.groupby(['officer_race','county_name']).agg({'count':'count'})\n",
    "\n",
    "df_race_mixed = copy(df_race_all_s)\n",
    "df_race_mixed['tot'] = df_race_all['count']\n",
    "df_race_mixed['stop_rate'] = df_race_mixed['count'] / df_race_mixed['tot']\n",
    "\n",
    "\n",
    "df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "df_race_mixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = separate_data( df_race_mixed, ['white'])['white']\n",
    "df.reset_index(level=[0,1], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.subject_race == 'black']['count'].sum())\n",
    "print(df['count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_race_stop(data, min_race, categories, threshold):\n",
    "\n",
    "    what_to_plot = 'stop_rate'\n",
    "\n",
    "    fig, ax_arr = plt.subplots(1, 3) # 2 graphs\n",
    "    fig.set_size_inches(17,5) # fig size\n",
    "    fig.suptitle(min_race.title() + \" people \"+ what_to_plot+\" among officers\".format(min_race))\n",
    "\n",
    "    for i, off_feat in enumerate(categories):\n",
    "\n",
    "        data_ = data[off_feat]\n",
    "        df_white_sub, df_minority = data_.loc['white'], data_.loc[min_race] #separate data\n",
    "        df_white_sub.reset_index(inplace=True), df_minority.reset_index(inplace=True) #reset index\n",
    "        df_merged = pd.merge(df_white_sub, df_minority, on='county_name', suffixes=['_white', '_minority']) # merge both\n",
    "\n",
    "        # remove where there are too little datapoints\n",
    "        cond_minority = df_merged['count_minority'] >= threshold\n",
    "\n",
    "        y = df_merged[what_to_plot + '_minority'][cond_minority]*100\n",
    "        total =  float(df_merged['count_minority'].sum())\n",
    "        print(total)\n",
    "        s = df_merged['count_minority'][cond_minority] #.apply(lambda x: x / total)\n",
    "\n",
    "        sns.histplot(y.repeat(s), ax=ax_arr[i], bins=8, kde=True)\n",
    "\n",
    "\n",
    "        ax_arr[i].set_xlabel(min_race.title() + what_to_plot + \" (%)\")\n",
    "        ax_arr[i].set_ylabel(\"Number of \" + min_race +\" stops\")\n",
    "\n",
    "\n",
    "        ax_arr[i].set_title(off_feat.title() +' officers')\n",
    "\n",
    "\n",
    "\n",
    "def plot_stop_rates(data, categories, threshold= 0):\n",
    "    for race in minority_race + ['white']:\n",
    "        plot_race_stop(data, race, categories, threshold)\n",
    "\n",
    "\n",
    "# separate data\n",
    "df_race_sep = separate_data(df_race_mixed, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot it \n",
    "plot_stop_rates(df_race_sep, officer_race, 0)"
   ]
  },
  {
   "source": [
    "# Veil of darkness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_CHARACTERISTIC = 'officer_race'\n",
    "\n",
    "df_veil = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "df_veil = remove_general_unused_columns(df_veil)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC , 'search_conducted']\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_veil.shape[0]))\n",
    "\n",
    "df_veil['date'] = pd.to_datetime(df_veil['date'])\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "starts = []\n",
    "ends = []\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015]\n",
    "\n",
    "for y in years:\n",
    "    starts.append(datetime.datetime.strptime(f\"01-10-{y}\", \"%d-%m-%Y\"))\n",
    "    ends.append(datetime.datetime.strptime(f\"30-10-{y}\", \"%d-%m-%Y\"))\n",
    "\n",
    "\n",
    "df_veil['month'] = df_veil['date'].apply(lambda x : np.sum([s <= x <= e for s,e in zip(starts, ends)]) > 0 )\n",
    "df_veil = df_veil[df_veil['month']]\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veiled = copy(df_veil)\n",
    "hours = [ f'{x}:' for x in range(17, 21)]\n",
    "\n",
    "df_veiled['time_bool'] = df_veiled['time'].apply(lambda x: x[0:3] in hours) \n",
    "df_veiled_both = df_veiled[ df_veiled['time_bool']]\n",
    "print(df_veiled_both.shape)\n",
    "\n",
    "df_veiled_both['time_period'] = df_veiled_both['time'].apply(lambda x : x[0:4])\n",
    "df_veiled_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_veiled_both['count'] = 1\n",
    "\n",
    "# df_veil_of_darkness = df_veiled_both.groupby(['officer_race','time_period','subject_race']).agg({'count':'count'})\n",
    "# df_veil_of_darkness_all = df_veiled_both.groupby(['officer_race','time_period']).agg({'count':'count'})\n",
    "\n",
    "# df_veil_of_darkness['tot'] = df_veil_of_darkness_all['count']\n",
    "# df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count'] / df_veil_of_darkness['tot']\n",
    "\n",
    "\n",
    "# # df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "# df_veil_of_darkness = df_veil_of_darkness.reset_index()\n",
    "\n",
    "# df_veil_of_darkness.head()\n",
    "\n",
    "\n",
    "# # df_veil_white = separate_data(df_veil_of_darkness, officer_race)\n",
    "# # df_veil_white['white'].head(10)\n",
    "\n",
    "df_veiled_both['count'] = 1\n",
    "\n",
    "df_veil_of_darkness = df_veiled_both.groupby(['time_period','subject_race']).agg({'count':'count'})\n",
    "df_veil_of_darkness_all = df_veiled_both.groupby('time_period').agg({'count':'count'})\n",
    "\n",
    "df_veil_of_darkness.reset_index(inplace=True)\n",
    "df_veil_of_darkness_all.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_veil_of_darkness['tot'] = df_veil_of_darkness_all['count']\n",
    "# df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count'] / df_veil_of_darkness['tot']\n",
    "\n",
    "\n",
    "# df_race_mixed = df_race_mixed.reorder_levels(['officer_race','subject_race','county_name'])\n",
    "\n",
    "# df_veil_of_darkness = df_veil_of_darkness.reset_index()\n",
    "\n",
    "df_veil_of_darkness = df_veil_of_darkness.merge(df_veil_of_darkness_all, on=['time_period'])\n",
    "df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count_x'] / df_veil_of_darkness['count_y']\n",
    "\n",
    "df_veil_of_darkness = df_veil_of_darkness[df_veil_of_darkness['subject_race'] == 'black']\n",
    "\n",
    "df_veil_of_darkness.head()\n",
    "\n",
    "# df_veil_white = separate_data(df_veil_of_darkness, officer_race)\n",
    "# df_veil_white['white'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veil_study = df_veil_of_darkness.reset_index()\n",
    "# df_veil_study = df_veil_white['white'].reset_index()\n",
    "df_veil_study['before_sunset'] = df_veil_study['time_period'].apply(lambda x: x < '20:1')\n",
    "df_veil_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = []\n",
    "for i in range(17, 21):\n",
    "    for j in range(0, 60, 10):\n",
    "        periods.append(f\"{i}:{int(j/10)}\")\n",
    "print(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10,5))\n",
    "\n",
    "data_black = df_veil_study[ df_veil_study['subject_race'] == 'black']\n",
    "\n",
    "sns.lineplot(x='time_period', y='black_stop_rate', data=data_black)\n",
    "plt.axvline('19:1', c='black', linestyle='dashed')\n",
    "\n",
    "data_black['before_sunset'] = data_black['time_period'].apply(lambda x : x < '19:1')\n",
    "\n",
    "data_black['time_period_v'] = data_black['time_period'].apply(lambda x : periods.index(x))\n",
    "\n",
    "data_black_before = data_black[data_black['before_sunset']]\n",
    "data_black_after = data_black[data_black['before_sunset'] == False]\n",
    "\n",
    "data_black_before.head()\n",
    "\n",
    "sns.regplot(x='time_period_v', y='black_stop_rate', data=data_black_before)\n",
    "sns.regplot(x='time_period_v', y='black_stop_rate', data=data_black_after)\n",
    "# sns.regplot(x=data_black_after['time_period'], y=data_black_after['black_stop_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# def plot_veil_of_darkness(data, period= ['01-12', '20-12'], sunset_time='17:3', hour_range=[15,20]):\n",
    "\n",
    "\n",
    "\n",
    "period= ['05-06', '28-07']\n",
    "sunset_time='20:1'\n",
    "hour_range=[18,22]\n",
    "\n",
    "\n",
    "df_veil = copy(data)\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "df_veil = remove_general_unused_columns(df_veil, columns_time)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC , 'search_conducted']\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "df_veil['date'] = pd.to_datetime(df_veil['date'])\n",
    "\n",
    "\n",
    "# select range of the period\n",
    "starts = []\n",
    "ends = []\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015]\n",
    "for y in years:\n",
    "    starts.append(datetime.datetime.strptime(f\"{period[0]}-{y}\", \"%d-%m-%Y\"))\n",
    "    ends.append(datetime.datetime.strptime(f\"{period[1]}-{y}\", \"%d-%m-%Y\"))\n",
    "\n",
    "df_veil['month'] = df_veil['date'].apply(lambda x : np.sum([s <= x <= e for s,e in zip(starts, ends)]) > 0 )\n",
    "df_veil = df_veil[df_veil['month']]\n",
    "\n",
    "# select hour range\n",
    "hours = [ f'{x}:' for x in range(hour_range[0], hour_range[1])]\n",
    "df_veiled['time_bool'] = df_veiled['time'].apply(lambda x: x[0:3] in hours) \n",
    "df_veiled_both = df_veiled[ df_veiled['time_bool']]\n",
    "df_veiled_both['time_period'] = df_veiled_both['time'].apply(lambda x : x[0:4])\n",
    "\n",
    "# group \n",
    "df_veiled_both['count'] = 1\n",
    "df_veil_of_darkness = df_veiled_both.groupby(['time_period','subject_race']).agg({'count':'count'})\n",
    "df_veil_of_darkness_all = df_veiled_both.groupby('time_period').agg({'count':'count'})\n",
    "df_veil_of_darkness.reset_index(inplace=True)\n",
    "df_veil_of_darkness_all.reset_index(inplace=True)\n",
    "df_veil_of_darkness = df_veil_of_darkness.merge(df_veil_of_darkness_all, on=['time_period'])\n",
    "df_veil_of_darkness['black_stop_rate'] = df_veil_of_darkness['count_x'] / df_veil_of_darkness['count_y']\n",
    "df_veil_of_darkness = df_veil_of_darkness[df_veil_of_darkness['subject_race'] == 'black']\n",
    "df_veil_study = df_veil_of_darkness.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# select only black people arrested\n",
    "data_black = df_veil_study[df_veil_study['subject_race'] == 'black']\n",
    "\n",
    "\n",
    "return data_black\n",
    "\n",
    "\n",
    "\n",
    "# df_black = plot_veil_of_darkness(df, period = period, sunset_time = sunset_time, hour_range = hour_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall astral\n",
    "# !pip install astral==1.10.1\n",
    "# !pip install astral\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm.notebook import tqdm, tqdm_notebook\n",
    "from datetime import datetime\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# s = sun(cityobserver, date=datetime.date())\n",
    "\n",
    "# def plot_veil_of_darkness(data, period= ['01-12', '20-12'], sunset_time='17:3', hour_range=[15,20]):\n",
    "CHOSEN_CHARACTERISTIC = 'officer_race'\n",
    "\n",
    "\n",
    "df_veil = copy(df)\n",
    "# remove unused columns\n",
    "columns_time = ['date','time']\n",
    "columns_to_drop = ['subject_sex', 'subject_age', 'arrest_made', 'citation_issued', 'warning_issued', 'outcome', 'frisk_performed', 'search_conducted']\n",
    "df_veil = remove_general_unused_columns(df_veil)\n",
    "df_veil.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', CHOSEN_CHARACTERISTIC ]\n",
    "df_veil.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_veil.shape[0]))\n",
    "\n",
    "df_veil['date'] = (df_veil['date'] + ' ' + df_veil['time']).progress_apply(lambda x : datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_veil.drop(columns=['time'], inplace=True)\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astral.sun as astralsun\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "from datetime import datetime\n",
    "\n",
    "city = LocationInfo(\"Orlando\")\n",
    "\n",
    "df_veil['dusk_time'] = df_veil['date'].progress_apply(lambda x : sun(city.observer, date=x)['dusk'].replace(tzinfo=None))\n",
    "df_veil['time_relative'] = df_veil['date'] - df_veil['dusk_time'] #.progress_apply(lambda x : x - )\n",
    "df_veil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "WIDTH = 20 # number of period of 15 minutes\n",
    "EXTEND= 2 # extend to take more data before the dusk time than after\n",
    "\n",
    "categories = [timedelta(minutes=15*i) for i in range(-WIDTH-EXTEND, WIDTH+1)]\n",
    "def get_category(timed):\n",
    "    for i, t in enumerate(categories):\n",
    "        if timed < t:\n",
    "            return i-WIDTH-EXTEND-1 if i else -1\n",
    "    return -1\n",
    "\n",
    "# Add a column with their time category (by small periods of 15 minutes. cat 0 is between 0 and 15 BEFORE dusk, 1 is 15 min just AFTER dusk, -1 is between 30 and 15 min BEFORE ). All cat = 0 are out of range arrests, clear them\n",
    "df_veil['time_cat'] = df_veil['time_relative'].progress_apply(lambda x : get_category(x))\n",
    "df_veil_cleaned = df_veil[df_veil['time_cat'] != -1]\n",
    "df_veil_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for_vod = copy(df_veil_cleaned)\n",
    "\n",
    "def get_time_category(time):\n",
    "    if time.minute < 7.5:\n",
    "        return f\"{time.hour}:00\"\n",
    "    elif 7.5 < time.minute < 22.5:\n",
    "        return f\"{time.hour}:15\"\n",
    "    elif 22.5 < time.minute < 37.5:\n",
    "        return f\"{time.hour}:30\"\n",
    "    elif 37.5 < time.minute < 52.5:\n",
    "        return f\"{time.hour}:45\"\n",
    "    else:\n",
    "        return f\"{time.hour + 1}:00\"\n",
    "\n",
    "# # Add a column with their dusk time moment\n",
    "# df_for_vod['dusk_exact_time'] = df_for_vod['dusk_time'].progress_apply(lambda x : x.time())\n",
    "# df_for_vod['dusk_category'] = df_for_vod['dusk_exact_time'].progress_apply(lambda x : get_time_category(x))\n",
    "# df_for_vod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veil_cleaned.to_csv('data_with_dusk.csv')\n",
    "df_veil_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_for_vod = pd.read_csv('data_with_dusk.csv')\n",
    "df_for_vod['date_obj'] = df_for_vod['date'].progress_apply(lambda x : datetime.strptime(x.split('.')[0], '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_vod['date_category'] = df_for_vod['date_obj'].progress_apply(lambda x : get_time_category(x))\n",
    "\n",
    "print(df_for_vod.shape)\n",
    "df_for_vod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_version = copy(df_for_vod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df_to_group):\n",
    "    df_to_group['count'] = 1\n",
    "\n",
    "    # group the categories\n",
    "    df_vod = df_to_group.groupby(['time_cat','subject_race']).agg({'count':'count'})\n",
    "    df_grouped_by_timecat = df_to_group.groupby('time_cat').agg({'count':'count'})\n",
    "\n",
    "    # merge both\n",
    "    df_vod.reset_index(inplace=True)\n",
    "    df_grouped_by_timecat.reset_index(inplace=True)\n",
    "    df_vod = df_vod.merge(df_grouped_by_timecat, on=['time_cat'])\n",
    "\n",
    "    # compute the stop_rate\n",
    "    df_vod['race_stop_rate'] = df_vod['count_x'] / df_vod['count_y']\n",
    "    return df_vod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vod_1sub_1off(data_o, time_range=[-8,7], plot=True, dusk_time=None, off_cat='all', filename='test.html', factor_size=None):\n",
    "    data = copy(data_o)\n",
    "    data = data[data['time_cat'].isin(range(time_range[0],time_range[1]))]\n",
    "    data = data[~data['time_cat'].isin(range(-1,0))]\n",
    "\n",
    "    data['time_cat'] = data['time_cat'] * 10\n",
    "    data['race_stop_rate'] = data['race_stop_rate'] * 100\n",
    "\n",
    "    # two different regressions\n",
    "    data_before = data[data['time_cat'] < -1]\n",
    "    data_after = data[data['time_cat'] > -1]\n",
    "\n",
    "    # calculate means\n",
    "    if data_before['count_y'].sum() == 0:\n",
    "        before_average = np.nan\n",
    "    else:\n",
    "        before_average = np.average(data_before['race_stop_rate'], weights=data_before['count_y'])\n",
    "    if data_after['count_y'].sum() == 0:\n",
    "        after_average = np.nan\n",
    "    else:\n",
    "        after_average = np.average(data_after['race_stop_rate'], weights=data_after['count_y'])\n",
    "\n",
    "    # plot\n",
    "    if plot:\n",
    "\n",
    "        # plot points\n",
    "        figure(figsize=(10,5))\n",
    "        ax = sns.scatterplot(x='time_cat', y='race_stop_rate', size='count_y', sizes=(20,200) ,data=data, color='black')\n",
    "        plt.axvline(0, c='black', linestyle='dashed')\n",
    "\n",
    "        # plot averages\n",
    "        plt.hlines(before_average, -80, -20)\n",
    "        plt.hlines(after_average, 0, 60)\n",
    "\n",
    "        # set axes\n",
    "        ax.set_xlabel('Time since dusk (min)')\n",
    "        ax.set_ylabel('Stopped drivers who are black (%)')\n",
    "\n",
    "        if dusk_time :\n",
    "            title = f\"Stops at {dusk_time} by {off_cat} officers\"\n",
    "        else:\n",
    "            title = f\"All stops by {off_cat} officers\"\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "        # plotly version\n",
    "        fig = make_subplots(rows=1, cols=1)\n",
    "        min_x, max_x = -90, 70\n",
    "        min_y, max_y = data['race_stop_rate'].min(), data['race_stop_rate'].max()\n",
    "        offset = (max_y - min_y)*0.1\n",
    "        min_y, max_y = min_y-offset, max_y+offset\n",
    "        figsize = (10,5)\n",
    "        \n",
    "        \n",
    "        color = px.colors.qualitative.Plotly[0]\n",
    "        m = data['count_y'].min()\n",
    "        M = data['count_y'].max()\n",
    "        sizes = data['count_y'] / data['count_y'].max() * 500\n",
    "        sizes /= 20\n",
    "        if factor_size is not None:\n",
    "            sizes *=  factor_size\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=data['time_cat'],\n",
    "            y=data['race_stop_rate'], \n",
    "            mode='markers',\n",
    "            marker=dict(size=sizes, opacity=0.9, color=color),\n",
    "            text='count: ' + data['count_y'].astype(str),\n",
    "            name='Number of stops',\n",
    "            ), \n",
    "            row=1, col=1\n",
    "            )\n",
    "\n",
    "        fig.add_shape(type=\"line\",\n",
    "            x0=0, y0= min_y, x1=0, y1=max_y,\n",
    "            line=dict(\n",
    "                color=\"Grey\",\n",
    "                width=1,\n",
    "                dash=\"dot\",\n",
    "            ), row=1, col=1,\n",
    "        )\n",
    "\n",
    "        lin = 15\n",
    "        xs = np.linspace(min_x, 0, lin)\n",
    "        ys = np.linspace(before_average, before_average, lin)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xs, y=ys,\n",
    "            mode='lines',\n",
    "            name='Weighted average',\n",
    "            text='Weighted mean: ' + str(before_average),\n",
    "            opacity=0.6,\n",
    "            line=dict(\n",
    "                color='Black',\n",
    "                width=3,\n",
    "                dash=\"solid\")\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        xs = np.linspace(0, max_x, lin)\n",
    "        ys = np.linspace(after_average, after_average, lin)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xs, y=ys,\n",
    "            mode='lines',\n",
    "            name='Weighted average',\n",
    "            text='Weighted mean: ' + str(after_average),\n",
    "            opacity=0.6,\n",
    "            line=dict(\n",
    "                color='Black',\n",
    "                width=3,\n",
    "                dash=\"solid\")\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text='Time since dusk (min)', range=[min_x, max_x], row=1, col=1)\n",
    "        fig.update_yaxes(title_text='Stopped drivers who are black (%)', range=[min_y, max_y], row=1, col=1)\n",
    "        print(min_y, max_y)\n",
    "\n",
    "        # fig.update_layout(autosize=True,width= widfigsize[0]*100*0.7, height=figsize[1]*100*0.8, title_text=title)\n",
    "        fig.update_layout(autosize=True, title_text=title)\n",
    "        fig.write_html(filename)\n",
    "        fig.show()\n",
    "    return before_average, after_average\n",
    "\n",
    "plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name=struct['name'], off_cat_values=struct['values'], sub_race= 'black', dusk_time='19:15', county_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1sub_Aoff(df__, off_cat_name, off_cat_values, sub_race, \\\n",
    "                            county_name=None, dusk_time=None, plot=True, filename='test.html'):\n",
    "\n",
    "    df_vod = copy(df__)\n",
    "\n",
    "    if type(off_cat_values) is dict:\n",
    "        officer_cat_values_list = [off_cat_values[x] for x in off_cat_values]\n",
    "        df_vod[off_cat_name+'_cat'] = df_vod[off_cat_name].apply(lambda x : get_off_cat(x, off_cat_values))\n",
    "        off_cat_name = off_cat_name+'_cat'\n",
    "        off_cat_values = officer_cat_values_list\n",
    "\n",
    "\n",
    "    # select only the data from one county\n",
    "    if county_name:\n",
    "        df_vod = df_vod[df_vod['county_name'] == county_name]\n",
    "\n",
    "    # select data from only one dusk time range\n",
    "    if dusk_time:\n",
    "        df_vod = df_vod[df_vod['date_category'] == dusk_time]\n",
    "\n",
    "    if df_vod.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    # for each cat of officer, plot the graph for the given subject race\n",
    "    list_hours = []\n",
    "\n",
    "    if off_cat_name != 'all':\n",
    "\n",
    "        for cat in off_cat_values:\n",
    "            df_ = group_data(df_vod[df_vod[off_cat_name] == cat])\n",
    "\n",
    "            # select only the data of one subject race\n",
    "            df_ = df_[df_['subject_race'] == sub_race]\n",
    "\n",
    "            if df_.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            tup = plot_vod_1sub_1off(df_, plot=plot, dusk_time = dusk_time, off_cat=cat, filename= cat + '_' + filename)\n",
    "            list_hours.append({'cat_off': cat ,'dusk': dusk_time, 'before':tup[0], 'after': tup[1]})\n",
    "        \n",
    "    else:\n",
    "        df_ = group_data(df_vod)\n",
    "        # select only the data of one subject race\n",
    "        df_ = df_[df_['subject_race'] == sub_race]\n",
    "\n",
    "        if df_.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        tup = plot_vod_1sub_1off(df_, plot=plot, dusk_time= dusk_time, filename=filename)\n",
    "        list_hours.append({'cat_off': 'all' ,'dusk': dusk_time, 'before':tup[0], 'after': tup[1]})\n",
    "    \n",
    "    return list_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_exploit = copy(df_for_vod)\n",
    "dusk_times = [f\"{h}:{m}\" for h in range(17,23) for m in ['00','15','30','45']]\n",
    "\n",
    "def get_off_cat(v, dic):\n",
    "    for i in dic:\n",
    "        if v < i:\n",
    "            return dic[i]\n",
    "    return -1\n",
    "\n",
    "# print(df_to_exploit.shape)\n",
    "# df_to_exploit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_each_cat(df__, cat_name, dic_cat, subject_race):\n",
    "    df_to_exploit = copy(df__)\n",
    "\n",
    "    if type(dic_cat) is dict:\n",
    "        officer_cat_values = [dic_cat[x] for x in dic_cat]\n",
    "        important_column = cat_name+'_cat'\n",
    "        df_to_exploit[important_column] = df_to_exploit[cat_name].apply(lambda x : get_off_cat(x, dic_cat))\n",
    "    else:\n",
    "        important_column = cat_name\n",
    "        officer_cat_values = dic_cat\n",
    "\n",
    "    stop_rates_each_period = []\n",
    "    for dt in tqdm(dusk_times):\n",
    "\n",
    "        v = plot_1sub_Aoff(df_to_exploit, plot=False,  off_cat_name=important_column, \\\n",
    "                 off_cat_values=officer_cat_values, sub_race= subject_race, dusk_time=dt)\n",
    "        if v != None:\n",
    "            for e in v:\n",
    "                stop_rates_each_period.append(e)\n",
    "\n",
    "    return pd.DataFrame(stop_rates_each_period), officer_cat_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_race = 'black'\n",
    "# cat_name = 'officer_yos'\n",
    "# dic_cat = { 2: 'recruit', 6:'new_officer', 10:'experienced_officer', 100: 'oldcop'}\n",
    "cat_name = 'officer_race'\n",
    "dic_cat = ['white', 'black', 'hispanic']\n",
    "# cat_name = 'officer_age'\n",
    "# dic_cat = { 25: 'teenager', 42:'young_adult', 48:'adult', 55:'old_adult', 100: 'pre-retirement'}#,  100: 'retired'}\n",
    "\n",
    "\n",
    "values, cats = precalculate_each_cat(df_to_exploit, cat_name=cat_name, dic_cat=dic_cat, subject_race=subject_race)\n",
    "values.head()\n",
    "# print_drop_Aoff(values, dic_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_of_hour(x):\n",
    "    s = x.split(':')\n",
    "    return int(s[0]) + float(s[1])/60\n",
    "\n",
    "\n",
    "def print_drop_Aoff(df__, off_cat, both_lines=False, filename='test.html'):\n",
    "    \n",
    "    colors = ['blue','black','red', 'green', 'yellow', 'pink']\n",
    "    df__['dusk_i'] = df__['dusk'].apply(lambda x : value_of_hour(x))\n",
    "    df__.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    print(df__.head(1))\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    def set_range_y_scale(serie):\n",
    "        min_y, max_y = serie.min(), serie.max()\n",
    "        offset = (max_y - min_y)*0.1\n",
    "        min_y, max_y = min_y-offset, max_y+offset\n",
    "        return min_y, max_y\n",
    "\n",
    "    figsize = (10,5)\n",
    "\n",
    "    min_y, max_y = 0.0 ,0.0\n",
    "    if off_cat:\n",
    "        for i, cat in enumerate(off_cat):\n",
    "            df_ = df__[df__['cat_off'] == cat]\n",
    "            if both_lines:\n",
    "                min_, max_ = set_range_y_scale(pd.concat([df_['before'],df_['after']]))\n",
    "                min_y = min_y if min_y<min_ else min_\n",
    "                max_y = max_y if max_y>max_ else max_\n",
    "                \n",
    "                x = df_['dusk_i']\n",
    "                y = df_['before']\n",
    "                label = cat + ' officers before dusk'\n",
    "                plt.plot(x, y, label=label, linestyle='dashed')\n",
    "\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=x, y=y,\n",
    "                    mode='lines',\n",
    "                    name=label,\n",
    "                    opacity=0.8,\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        dash=\"dash\")\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "\n",
    "                \n",
    "                x = df_['dusk_i']\n",
    "                y = df_['after']\n",
    "                label = cat + ' officers after dusk'\n",
    "                plt.plot(x, y, label=label)\n",
    "\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=x, y=y,\n",
    "                    mode='lines',\n",
    "                    name=label,\n",
    "                    opacity=0.8,\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        dash=\"solid\")\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                x = df_['dusk_i']\n",
    "                y = df_['before'] - df_['after']\n",
    "                label = cat + ' officers'\n",
    "                plt.plot(x, y, label=label)\n",
    "                \n",
    "                min_, max_ = set_range_y_scale(y)\n",
    "                min_y = min_y if min_y<min_ else min_\n",
    "                max_y = max_y if max_y>max_ else max_\n",
    "                # plt.hlines(df_['before'].mean() - df_['after'].mean(), 17.25, 21.50,  linestyle='dashed', color=colors[i])\n",
    "\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=x, y=y,\n",
    "                    mode='lines',\n",
    "                    name=label,\n",
    "                    opacity=0.8,\n",
    "                    line=dict(\n",
    "                        width=2,\n",
    "                        dash=\"solid\")\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        df_ = df__.group(columns=['dusk']).aggr({'before':'mean', 'after':'mean'})\n",
    "        \n",
    "\n",
    "        x = df_['dusk_i']\n",
    "        y = df_['before'] - df_['after']\n",
    "        label = 'all officers'\n",
    "        min_, max_ = set_range_y_scale(y)\n",
    "        min_y = min_y if min_y<min_ else min_\n",
    "        max_y = max_y if max_y>max_ else max_\n",
    "        plt.plot(x, y, label=label)\n",
    "        # plt.hlines(df_['before'].mean() - df_['after'].mean(), 17.25, 21.50,  linestyle='dashed', color=colors[i])\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y,\n",
    "            mode='lines',\n",
    "            name=label,\n",
    "            opacity=0.8,\n",
    "            line=dict(\n",
    "                width=2,\n",
    "                dash=\"solid\")\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    fig.add_shape(type=\"line\",\n",
    "        x0=22, y0= 0, x1=17, y1=0,\n",
    "        line=dict(\n",
    "            color=\"Grey\",\n",
    "            width=2,\n",
    "            dash=\"dot\",\n",
    "        ), row=1, col=1,\n",
    "    )\n",
    "\n",
    "    min_x, max_x = df_['dusk_i'].min(), df_['dusk_i'].max()\n",
    "    fig.update_xaxes(title_text='Time period (h)', range=[min_x-0.2, max_x+0.2], row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Stop rate drop of black people at each time period (%)', range=[min_y, max_y], row=1, col=1)\n",
    "    print(min_y, max_y)\n",
    "\n",
    "    # fig.update_layout(autosize=True,width= widfigsize[0]*100*0.7, height=figsize[1]*100*0.8, title_text=title)\n",
    "    fig.update_layout(autosize=True, title_text='Stop rate drop of black people at each time period')\n",
    "    fig.write_html(filename)\n",
    "    fig.show()\n",
    "\n",
    "    plt.hlines(0, 17, 22, linestyle='dashed', color='black')\n",
    "    plt.ylabel('Stop rate drop of black people at each time period (%)')\n",
    "    plt.xlabel('Time period (h)')\n",
    "    plt.title('Stop rate drop of black people at each time period')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## TO BE PRESENTED"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First plot : n average on the year, for all officers: see that the vod works"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_exploit = copy(df_new_version)\n",
    "\n",
    "plot_1sub_Aoff(df_new_version, plot=True,  off_cat_name='all', \\\n",
    "                 off_cat_values=['white', 'black', 'hispanic'], sub_race= 'black', dusk_time='18:00', county_name=None, filename='basic_1800.html')"
   ]
  },
  {
   "source": [
    "Now lets try to get ride of the hour schedule bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name='all', \\\n",
    "                 off_cat_values=[], sub_race= 'black', dusk_time='18:00', county_name=None)\n",
    "plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name='all', \\\n",
    "                 off_cat_values=[], sub_race= 'black', dusk_time='19:15', county_name=None)\n",
    "plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name='all', \\\n",
    "                 off_cat_values=[], sub_race= 'black', dusk_time='19:45', county_name=None)\n",
    "plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name='all', \\\n",
    "                 off_cat_values=[], sub_race= 'black', dusk_time='20:30', county_name=None)"
   ]
  },
  {
   "source": [
    "Not always consistent: lets show the difference per dusk time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, cats = precalculate_each_cat(df_to_exploit, cat_name='all', dic_cat=['all'], subject_race=subject_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_drop_Aoff(values, cats, filename='stop_rate_drop_at_eat.html')"
   ]
  },
  {
   "source": [
    "Let's try to find out if there are differences between officer races. First define the several categories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race_struct =  {\n",
    "    'name': 'officer_race',\n",
    "    'values': ['white', 'black', 'hispanic']\n",
    "}\n",
    "officer_yos_struct =  {\n",
    "    'name': 'officer_yos',\n",
    "    'values': {2: '0 - 2', 6:' 2 - 6', 10:' 6 - 10', 100: ' > 10'}\n",
    "}\n",
    "officer_age_struct =  {\n",
    "    'name': 'officer_age',\n",
    "    'values': { 25: '< 25', 35:'25 - 35', 45:'35 - 45', 55:'45 - 55', 100: '> 55'}\n",
    "}\n",
    "officer_sex_struct =  {\n",
    "    'name': 'officer_sex',\n",
    "    'values': ['male', 'female']\n",
    "}\n",
    "struct = officer_yos_struct \n",
    "subject_race='black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_1sub_Aoff(df_to_exploit, plot=True,  off_cat_name=struct['name'], off_cat_values=struct['values'], sub_race= 'black', dusk_time='19:15', county_name=None, filename='1915_white.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, cats = precalculate_each_cat(df_to_exploit, cat_name=struct['name'], dic_cat=struct['values'], subject_race=subject_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_drop_Aoff(values, cats, False, filename='html/officer_yos_struct.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15,5))\n",
    "print_drop_Aoff(values, cats, both_lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preprocess for grouping\n",
    "data['search_rate'] = data['search_conducted']\n",
    "data = data.astype({'search_rate': float})\n",
    "data['count'] = 1 # to count occurences\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_yos['age_category'] = df_yos['officer_yos'].apply(lambda x : officer_experience_level[0] if x < thresholds_experience[0] else (officer_experience_level[1] if x < thresholds_experience[1] else officer_experience_level[2]))\n",
    "df_yos_all = df_yos.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Logistic regression of characteristics of officers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_raw = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_log_raw = remove_general_unused_columns(df_log_raw)\n",
    "df_log_raw.drop(columns=['arrest_made', 'citation_issued','warning_issued', 'outcome', 'frisk_performed'], inplace=True)\n",
    "df_log_raw.dropna(inplace=True, subset=['search_conducted'])\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_age', 'officer_yos', 'officer_age']\n",
    "for feat in important_features:\n",
    "    m = df_log_raw[feat].mean()\n",
    "    df_log_raw[feat] = df_log_raw[feat].fillna((m))\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_log_raw.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_log_raw)\n",
    "\n",
    "df_log_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for regression\n",
    "df_log = copy(df_log_raw)\n",
    "\n",
    "print('Processing sub races')\n",
    "sub_races = list(df_log['subject_race'].unique())\n",
    "for race in sub_races:\n",
    "    df_log['subject_' + (race if isinstance(race, str) else 'nan')] = (df_log['subject_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off races')\n",
    "off_races = list(df_log['officer_race'].unique())\n",
    "for race in off_races:\n",
    "    df_log['officer_' + (race if isinstance(race, str) else 'nan')] = (df_log['officer_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing sub genders')\n",
    "sub_genders = list(df_log['subject_sex'].unique())\n",
    "for gender in sub_genders:\n",
    "    df_log['subject_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['subject_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off genders')\n",
    "off_genders = list(df_log['officer_sex'].unique())\n",
    "for gender in off_genders:\n",
    "    df_log['officer_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['officer_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off yos')\n",
    "cat_exp = [0, 2, 6, 10, 15, 100]\n",
    "for infi in range(len(cat_exp) -1):\n",
    "    df_log['officer_exp_' + str(cat_exp[infi]) ] = ( df_log['officer_yos'].between(cat_exp[infi],cat_exp[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off age')\n",
    "cat_age = [15, 25, 35, 45, 55, 70, 100]\n",
    "for infi in range(len(cat_age) -1):\n",
    "    df_log['officer_age_' + str(cat_age[infi]) ] = ( df_log['officer_age'].between(cat_age[infi],cat_age[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "\n",
    "print('Processing search')\n",
    "df_log['search_conducted'] = df_log['search_conducted'].apply(lambda x : int(x))\n",
    "\n",
    "print('Removing old columns')\n",
    "df_log.drop(columns=['subject_race', 'officer_race', 'subject_sex', 'officer_sex', 'officer_yos', 'officer_age'], inplace=True)\n",
    "\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = df_log['county_name'].unique()\n",
    "maxi = 0\n",
    "maxi_c = 0\n",
    "for c in counties:\n",
    "    v = df_log[df_log['county_name'] == c].shape[0]\n",
    "    if v > maxi:\n",
    "        maxi = v\n",
    "        maxi_c = c\n",
    "\n",
    "print(maxi_c, maxi )\n",
    "\n",
    "df_log = df_log[df_log['county_name'] == maxi_c].drop(columns='county_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_log['search_conducted'].to_numpy()\n",
    "x = df_log.drop(columns='search_conducted').to_numpy()\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x, y)\n",
    "params = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters of logistic regression are:\")\n",
    "for i, col in enumerate(df_log.drop(columns='search_conducted').columns):\n",
    "    print(\" - {} : {:.3f} \".format(col,params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance, DMatrix\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model).set_yticklabels(df_log.drop(columns='search_conducted').columns[:23])"
   ]
  },
  {
   "source": [
    "We see that experienced officers do not search often people. This may be due because they are at a higher level, so they do not do the search themselves. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Old stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_officer_race(data, race):\n",
    "    data_ = data[race]\n",
    "    df_white_sub, df_black_sub, df_hispanic = data_.loc['white'], data_.loc['black'], data_.loc['hispanic'] #separate data\n",
    "    df_white_sub.reset_index(inplace=True), df_black_sub.reset_index(inplace=True), df_hispanic.reset_index(inplace=True) #reset index\n",
    "    df_merged = pd.merge(df_white_sub, df_black_sub, on='county_name', suffixes=['', '_black'])\n",
    "    df_merged = pd.merge(df_merged, df_hispanic, on='county_name', suffixes=['_white', '_hispanic'])\n",
    "    fig, ax_arr = plt.subplots(1, 2) # 2 graphs\n",
    "    fig.set_size_inches(9,5) # fig size\n",
    "\n",
    "    fig.suptitle(\"Minorities search rates of {} officers\".format(race))\n",
    "\n",
    "    ax_arr[0].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_black']*100)\n",
    "    ax_arr[0].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[0].set_ylabel(\"Black search rate (%)\")\n",
    "\n",
    "    ax_arr[1].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_hispanic']*100)\n",
    "    ax_arr[1].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[1].set_ylabel(\"Black search rate (%)\")\n",
    "    \n",
    "\n",
    "for race in officer_race:\n",
    "    plot_officer_race(df_officers, race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df_to_group):\n",
    "    df_to_group['count'] = 1\n",
    "\n",
    "    # group the categories\n",
    "    df_vod = df_to_group.groupby(['time_cat','subject_race']).agg({'count':'count'})\n",
    "    df_grouped_by_timecat = df_to_group.groupby('time_cat').agg({'count':'count'})\n",
    "\n",
    "    # merge both\n",
    "    df_vod.reset_index(inplace=True)\n",
    "    df_grouped_by_timecat.reset_index(inplace=True)\n",
    "    df_vod = df_vod.merge(df_grouped_by_timecat, on=['time_cat'])\n",
    "\n",
    "    # compute the stop_rate\n",
    "    df_vod['race_stop_rate'] = df_vod['count_x'] / df_vod['count_y']\n",
    "    return df_vod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vod_1sub_1off(data_o, time_range=[-8,7], plot=True, dusk_time=None, off_cat='all'):\n",
    "    data = copy(data_o)\n",
    "    data = data[data['time_cat'].isin(range(time_range[0],time_range[1]))]\n",
    "    data = data[~data['time_cat'].isin(range(-1,0))]\n",
    "\n",
    "    data['time_cat'] = data['time_cat'] * 10\n",
    "    data['race_stop_rate'] = data['race_stop_rate'] * 100\n",
    "\n",
    "    # two different regressions\n",
    "    data_before = data[data['time_cat'] < -1]\n",
    "    data_after = data[data['time_cat'] > -1]\n",
    "\n",
    "    # calculate means\n",
    "    before_average = data_before['race_stop_rate'].mean()\n",
    "    after_average = data_after['race_stop_rate'].mean()\n",
    "\n",
    "    # plot\n",
    "    if plot:\n",
    "\n",
    "        # plot points\n",
    "        figure(figsize=(10,5))\n",
    "        ax = sns.scatterplot(x='time_cat', y='race_stop_rate', size='count_y', sizes=(20,200) ,data=data, color='black')\n",
    "        plt.axvline(0, c='black', linestyle='dashed')\n",
    "\n",
    "        # plot averages\n",
    "        plt.hlines(before_average, -80, -20)\n",
    "        plt.hlines(after_average, 0, 60)\n",
    "\n",
    "        # set axes\n",
    "        ax.set_xlabel('Time since dusk (min)')\n",
    "        ax.set_ylabel('Percentage of stopped drivers who are black')\n",
    "\n",
    "        if dusk_time :\n",
    "            ax.set_title(f\"Dusk time at {dusk_time} : stops by {off_cat} officers\")\n",
    "        else:\n",
    "            ax.set_title(f\"All dusk times : stops by {off_cat} officers\")\n",
    "\n",
    "    return before_average, after_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}