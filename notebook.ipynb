{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "state = 'fl_statewide_2020_04_01.csv'\n",
    "state2 = 'ca_long_beach_2020_04_01.csv'"
   ]
  },
  {
   "source": [
    "# Preprocessing whole dataset (do not execute if working on full data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(folder + state)\n",
    "print(df_full.columns)"
   ]
  },
  {
   "source": [
    "Reducing the amount of data for experimentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_file_path = folder + state.split('.')[0] + \"_cut.csv\"\n",
    "total_size = df_full.shape[0]\n",
    "df = df_full.sample(n=int(total_size/100))\n",
    "print(\"Full dataset of size {} was reduced to subset of {} elements.\".format(total_size, df.shape[0]))\n",
    "df.to_csv(cut_file_path, index = False)"
   ]
  },
  {
   "source": [
    "# Load the data (currently loading all data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df =  pd.read_csv(folder + state)\n",
    "print(\"Dataset is composed of {} stops. Columns are: \\n\".format(df.shape[0]))\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] != np.float64:\n",
    "        val = df[col].unique()\n",
    "        if len(val) > 20:\n",
    "            print('{} \\t\\t: too much different values'.format(col))\n",
    "        else:\n",
    "            print('{} \\t\\t: values are: {}'.format(col if len(col)>15 else col + \"\\t\\t\", val))\n",
    "df = df.rename(columns={'officer_years_of_service': 'officer_yos'})"
   ]
  },
  {
   "source": [
    "# Preprocess to compare search rates\n",
    "\n",
    "Calculate search rates for each officer race and each subject race across each county"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# General functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_race = ['black', 'hispanic']\n",
    "\n",
    "def remove_general_unused_columns(data):\n",
    "    columns_unused = ['officer_id_hash', 'vehicle_registration_state', 'type']\n",
    "    columns_reasons = ['reason_for_stop', 'reason_for_search', 'notes', 'violation', 'search_basis']\n",
    "    columns_raw = ['raw_EnforcementAction', 'raw_SearchType', 'raw_Ethnicity', 'raw_row_number_new', 'raw_Race', 'raw_row_number_old', 'raw_row_number']\n",
    "    columns_geography = ['location', 'date','time', 'department_name', 'unit']\n",
    "    return data.drop(columns=columns_unused + columns_reasons + columns_raw + columns_geography)\n",
    "\n",
    "def print_search_rate(data):\n",
    "    number_stops = data['search_conducted'].shape[0]\n",
    "    number_search_conducted = data[data['search_conducted'] == True].shape[0]\n",
    "    print('Data contains {} stops and {} of them ({}%) resulted in searches.'.format(number_stops, number_search_conducted, 100 * float(number_search_conducted)/number_stops))\n",
    "\n",
    "def preprocess_for_grouping(data):\n",
    "    data['search_rate'] = data['search_conducted']\n",
    "    data = data.astype({'search_rate': float})\n",
    "    data['count'] = 1 # to count occurences\n",
    "    return data\n",
    "\n",
    "def separate_data(data, categories):\n",
    "    df = {}\n",
    "    for exp in categories:\n",
    "        df[exp] = data.loc[exp]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_race(data, min_race, categories, threshold):\n",
    "\n",
    "    fig, ax_arr = plt.subplots(1, 3) # 2 graphs\n",
    "    fig.set_size_inches(14,5) # fig size\n",
    "    fig.suptitle(min_race.title() + \" people search rates among officers\".format(min_race))\n",
    "\n",
    "    for i, off_feat in enumerate(categories):\n",
    "\n",
    "        data_ = data[off_feat]\n",
    "        df_white_sub, df_minority = data_.loc['white'], data_.loc[min_race] #separate data\n",
    "        df_white_sub.reset_index(inplace=True), df_minority.reset_index(inplace=True) #reset index\n",
    "        df_merged = pd.merge(df_white_sub, df_minority, on='county_name', suffixes=['_white', '_minority']) # merge both\n",
    "\n",
    "        # remove where there are too little datapoints\n",
    "        cond_minority = df_merged['count_minority'] >= threshold\n",
    "\n",
    "        x = df_merged['search_rate_white'][cond_minority]*100\n",
    "        y = df_merged['search_rate_minority'][cond_minority]*100\n",
    "        s = df_merged['count_minority'][cond_minority]/100\n",
    "\n",
    "        ax_arr[i].scatter(x, y, s=s, c=\"None\", edgecolors='black', linewidth=0.4)\n",
    "        ax_arr[i].set_xlabel(\"White search rate (%)\")\n",
    "        ax_arr[i].set_ylabel(min_race.title() + \" search rate (%)\")\n",
    "\n",
    "\n",
    "        #plot regression\n",
    "        a, b, r, p_value, std_err = linregress(x, y)\n",
    "        sns.regplot(x=x, y=y, ax=ax_arr[i], label='{:.1f}*x + {:.1f}, r={:.2f}'.format(a,b,r), scatter=False).legend(loc=\"best\")\n",
    "\n",
    "        ax_arr[i].set_title(off_feat.title() +' officers')\n",
    "\n",
    "        # draw dotted line\n",
    "        max_ = df_merged['search_rate_minority'][cond_minority].max()\n",
    "        line = np.arange(0, max_ * 100, max_)\n",
    "        ax_arr[i].plot(line, line, c='black', linestyle=(0,(5,5)), linewidth=1)\n",
    "\n",
    "\n",
    "def plot_search_rates(data, categories, threshold=500):\n",
    "    for race in minority_race:\n",
    "        plot_race(data, race, categories, threshold)"
   ]
  },
  {
   "source": [
    "# Race of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_race = ['white', 'black', 'hispanic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_race = remove_general_unused_columns(df_race)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_race', 'search_conducted']\n",
    "df_race.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_race.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_race)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_race = preprocess_for_grouping(df_race)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_race_all = df_race.groupby(['officer_race','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_race_sep = separate_data(df_race_all, officer_race)\n",
    "df_race_sep[officer_race[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_race_sep, officer_race, 5000)"
   ]
  },
  {
   "source": [
    "# Experience of officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_experience_level = ['young', 'experienced', 'old']\n",
    "thresholds_experience = [2, 9]"
   ]
  },
  {
   "source": [
    "Preprocess the data to have what is needed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yos = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_yos = remove_general_unused_columns(df_yos)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_yos', 'search_conducted']\n",
    "df_yos.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_yos.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_yos)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_yos = preprocess_for_grouping(df_yos)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_yos['age_category'] = df_yos['officer_yos'].apply(lambda x : officer_experience_level[0] if x < thresholds_experience[0] else (officer_experience_level[1] if x < thresholds_experience[1] else officer_experience_level[2]))\n",
    "df_yos_all = df_yos.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_yos_sep = separate_data(df_yos_all, officer_experience_level)\n",
    "df_yos_sep[officer_experience_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_yos_sep, officer_experience_level, 5000)"
   ]
  },
  {
   "source": [
    "# Age of the officer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_age_level = ['young', 'experienced', 'old']\n",
    "thresholds_age = [30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_age = remove_general_unused_columns(df_age)\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_race', 'officer_age', 'search_conducted']\n",
    "df_age.dropna(inplace=True, subset=important_features)\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_age.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_age)\n",
    "\n",
    "# preprocess for grouping\n",
    "df_age = preprocess_for_grouping(df_age)\n",
    "\n",
    "# add specific column for this type of analyzis\n",
    "df_age['age_category'] = df_age['officer_age'].apply(lambda x : officer_age_level[0] if x < thresholds_age[0] else (officer_age_level[1] if x < thresholds_age[1] else officer_age_level[2]))\n",
    "df_age_all = df_age.groupby(['age_category','subject_race','county_name']).agg({'search_rate': 'mean', 'count':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data\n",
    "df_age_sep = separate_data(df_age_all, officer_age_level)\n",
    "df_age_sep[officer_age_level[0]].head(2)\n",
    "\n",
    "# plot it \n",
    "plot_search_rates(df_age_sep, officer_age_level, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Logistic regression of characteristics of officers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_raw = copy(df)\n",
    "\n",
    "# remove unused columns\n",
    "df_log_raw = remove_general_unused_columns(df_log_raw)\n",
    "df_log_raw.drop(columns=['arrest_made', 'citation_issued','warning_issued', 'outcome', 'frisk_performed'], inplace=True)\n",
    "df_log_raw.dropna(inplace=True, subset=['search_conducted'])\n",
    "\n",
    "# make sure that required data are present (drop if nan values in those columns)\n",
    "important_features = ['subject_age', 'officer_yos', 'officer_age']\n",
    "for feat in important_features:\n",
    "    m = df_log_raw[feat].mean()\n",
    "    df_log_raw[feat] = df_log_raw[feat].fillna((m))\n",
    "print('Cleaned subset is composed of {} datapoints'.format(df_log_raw.shape[0]))\n",
    "\n",
    "# overview of all the data / global search rate\n",
    "print_search_rate(df_log_raw)\n",
    "\n",
    "df_log_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for regression\n",
    "df_log = copy(df_log_raw)\n",
    "\n",
    "print('Processing sub races')\n",
    "sub_races = list(df_log['subject_race'].unique())\n",
    "for race in sub_races:\n",
    "    df_log['subject_' + (race if isinstance(race, str) else 'nan')] = (df_log['subject_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off races')\n",
    "off_races = list(df_log['officer_race'].unique())\n",
    "for race in off_races:\n",
    "    df_log['officer_' + (race if isinstance(race, str) else 'nan')] = (df_log['officer_race'] == race).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing sub genders')\n",
    "sub_genders = list(df_log['subject_sex'].unique())\n",
    "for gender in sub_genders:\n",
    "    df_log['subject_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['subject_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off genders')\n",
    "off_genders = list(df_log['officer_sex'].unique())\n",
    "for gender in off_genders:\n",
    "    df_log['officer_' + (gender if isinstance(gender, str) else 'nan')] = (df_log['officer_sex'] == gender).apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off yos')\n",
    "cat_exp = [0, 2, 6, 10, 15, 100]\n",
    "for infi in range(len(cat_exp) -1):\n",
    "    df_log['officer_exp_' + str(cat_exp[infi]) ] = ( df_log['officer_yos'].between(cat_exp[infi],cat_exp[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "print('Processing off age')\n",
    "cat_age = [15, 25, 35, 45, 55, 70, 100]\n",
    "for infi in range(len(cat_age) -1):\n",
    "    df_log['officer_age_' + str(cat_age[infi]) ] = ( df_log['officer_age'].between(cat_age[infi],cat_age[infi+1], inclusive=[True, False]) ) .apply(lambda x : int(x))\n",
    "\n",
    "\n",
    "print('Processing search')\n",
    "df_log['search_conducted'] = df_log['search_conducted'].apply(lambda x : int(x))\n",
    "\n",
    "print('Removing old columns')\n",
    "df_log.drop(columns=['subject_race', 'officer_race', 'subject_sex', 'officer_sex', 'officer_yos', 'officer_age'], inplace=True)\n",
    "\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = df_log['county_name'].unique()\n",
    "maxi = 0\n",
    "maxi_c = 0\n",
    "for c in counties:\n",
    "    v = df_log[df_log['county_name'] == c].shape[0]\n",
    "    if v > maxi:\n",
    "        maxi = v\n",
    "        maxi_c = c\n",
    "\n",
    "print(maxi_c, maxi )\n",
    "\n",
    "df_log = df_log[df_log['county_name'] == maxi_c].drop(columns='county_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_log['search_conducted'].to_numpy()\n",
    "x = df_log.drop(columns='search_conducted').to_numpy()\n",
    "print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x, y)\n",
    "params = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters of logistic regression are:\")\n",
    "for i, col in enumerate(df_log.drop(columns='search_conducted').columns):\n",
    "    print(\" - {} : {:.3f} \".format(col,params[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance, DMatrix\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model).set_yticklabels(df_log.drop(columns='search_conducted').columns[:23])"
   ]
  },
  {
   "source": [
    "We see that experienced officers do not search often people. This may be due because they are at a higher level, so they do not do the search themselves. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Old stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_officer_race(data, race):\n",
    "    data_ = data[race]\n",
    "    df_white_sub, df_black_sub, df_hispanic = data_.loc['white'], data_.loc['black'], data_.loc['hispanic'] #separate data\n",
    "    df_white_sub.reset_index(inplace=True), df_black_sub.reset_index(inplace=True), df_hispanic.reset_index(inplace=True) #reset index\n",
    "    df_merged = pd.merge(df_white_sub, df_black_sub, on='county_name', suffixes=['', '_black'])\n",
    "    df_merged = pd.merge(df_merged, df_hispanic, on='county_name', suffixes=['_white', '_hispanic'])\n",
    "    fig, ax_arr = plt.subplots(1, 2) # 2 graphs\n",
    "    fig.set_size_inches(9,5) # fig size\n",
    "\n",
    "    fig.suptitle(\"Minorities search rates of {} officers\".format(race))\n",
    "\n",
    "    ax_arr[0].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_black']*100)\n",
    "    ax_arr[0].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[0].set_ylabel(\"Black search rate (%)\")\n",
    "\n",
    "    ax_arr[1].scatter(df_merged['search_rate_white']*100, df_merged['search_rate_hispanic']*100)\n",
    "    ax_arr[1].set_xlabel(\"White search rate (%)\")\n",
    "    ax_arr[1].set_ylabel(\"Black search rate (%)\")\n",
    "    \n",
    "\n",
    "for race in officer_race:\n",
    "    plot_officer_race(df_officers, race)"
   ]
  }
 ]
}