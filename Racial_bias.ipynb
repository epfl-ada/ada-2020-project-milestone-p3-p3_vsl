{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Racial bias analysis in police stops.\n",
    "\n",
    "We want to study the data used by stanford in their paper to check if the characteristics of a police officer are linked to a potential racial bias in stops.\n",
    "\n",
    "To this end, we will use the stops data of the state police of Florida, and analyse behaviors towards white, black, or hispanic people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "- [Data exploration](#Exploration)\n",
    "- [Statewide bias score](#Statewide_score)\n",
    "- [County adjusted bias score](#County_score)\n",
    "- [Veil of darkness further study](#Veil_of_darkness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's gather and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\envs\\ada\\lib\\site-packages\\tqdm\\std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "state = folder + 'fl_statewide.csv.zip'\n",
    "\n",
    "keep_columns = ['date', 'time', 'county_name', 'subject_age', 'subject_race', 'subject_sex', 'officer_id_hash', 'officer_age', 'officer_race', 'officer_sex', 'officer_years_of_service', 'arrest_made', 'citation_issued', 'warning_issued', 'frisk_performed', 'search_conducted']\n",
    "mandatory_columns = ['date', 'time', 'subject_age', 'subject_race', 'subject_sex', 'officer_id_hash', 'officer_age', 'officer_race', 'officer_sex', 'officer_years_of_service', 'arrest_made', 'citation_issued', 'warning_issued', 'search_conducted']\n",
    "minorities = ['white', 'hispanic', 'black']\n",
    "boolean_columns = ['arrest_made', 'citation_issued', 'warning_issued', 'frisk_performed', 'search_conducted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_booleans(df):\n",
    "    \"\"\" type a column in boolean if possible to reduce size and handability of dataframe\n",
    "    \"\"\"\n",
    "    global boolean_columns\n",
    "    for col in boolean_columns:\n",
    "        if df_full[col].isna().sum() == 0:\n",
    "            df_full[col] = df_full[col].astype(bool)\n",
    "        else:\n",
    "            print(f\"Cannot convert {col} columns to boolean\")\n",
    "\n",
    "def print_info_df(df):\n",
    "    \"\"\" print summary of dataframe and values in columns if not too long\n",
    "    \"\"\"\n",
    "    print(\"Dataset is composed of {} stops. Columns are: \\n\".format(df.shape[0]))\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] != np.float64:\n",
    "            val = df[col].unique()\n",
    "            if len(val) > 20:\n",
    "                print('{} \\t\\t: too much different values'.format(col))\n",
    "            else:\n",
    "                print('{} \\t\\t: values are: {}'.format(col if len(col)>15 else col + \"\\t\\t\", val))\n",
    "\n",
    "def generate_smaller_data(df, keep_ratio, path):\n",
    "    \"\"\" Write new csv of reduced size in path and returns it\n",
    "    \"\"\"\n",
    "    total_size = df.shape[0]\n",
    "    df_red = df.sample(n=int(total_size * keep_ratio))\n",
    "    df_red.to_csv(path, index = False)\n",
    "    return df_red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning florida dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all dataset\n",
    "df_full = pd.read_csv(state)\n",
    "print(len(df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(columns=df_full.columns.difference(keep_columns), inplace=True) # drop unused columns\n",
    "df_full.dropna(subset=mandatory_columns, how='any', inplace=True) # drop nan values in mandatory columns\n",
    "df_full['date'] = pd.to_datetime(df_full['date']) # to datetime\n",
    "df_full['year'] = df_full['date'].dt.to_period('y')\n",
    "df_full = df_full.rename(columns={'officer_years_of_service': 'officer_yos'})\n",
    "\n",
    "print(len(df_full))\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = Exploration></a>\n",
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp on the data : is there spelling mistakes for gender, race; nan values; ...\n",
    "print_info_df(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep same minorities as papers \n",
    "# df_full = df_full[df_full['subject_race'].isin(minorities)]\n",
    "df_full = df_full[df_full['officer_race'].isin(minorities)]\n",
    "type_booleans(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = Statewide_score></a>\n",
    "# Bias score\n",
    "## Goal\n",
    "The goal here is to determined *how* the characteristics of an officer influence its bias towards minorities \n",
    "\n",
    "## How\n",
    "- An officer : arrest over a N-year period\n",
    "- Raw bias score for officer o towards minority m $ B(o,m) = \\frac{N_{stops~of~m}}{N_{total~stops~over~the~period}} $\n",
    "- Strong assumption: $median(\\{B(o,m) / o \\in S\\})$ is actually the proportion of the population of $S$ which is from minority $m$ \n",
    "- Bias score for minority $m$ for an officer in a set of officers of region $S$ : $ B_m = \\frac{N_{stops~of~m}}{N_{total~stops~over~the~period}} - median(\\{B(o,m) / o \\in S\\})$\n",
    "\n",
    "The study is held this way : \n",
    "- $S$ is statewide : see the coefficient statewide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of first officer dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_officers = df_full.groupby(['year', 'officer_id_hash', 'officer_race', 'officer_sex'])['officer_yos', 'officer_age']\n",
    "df_officers = df_officers.min().reset_index()\n",
    "df_officers.set_index(['year', 'officer_id_hash'], inplace=True, verify_integrity=True)\n",
    "df_officers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataframe linking (year, officer) to their number of arrest of minorities\n",
    "df_yearly = df_full.groupby(['year', 'officer_id_hash', 'subject_race'])['date'].count().to_frame().reset_index()\n",
    "df_yearly.rename(columns={'date':'stops'}, inplace=True)\n",
    "df_yearly = df_yearly.pivot_table(columns='subject_race', values='stops', index=['year', 'officer_id_hash'], fill_value=0)\n",
    "df_yearly['total'] = df_yearly.sum(axis=1)\n",
    "df_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop officers with too few arrest\n",
    "stop_threshold = 300\n",
    "df_yearly = df_yearly[df_yearly['total'] > stop_threshold]\n",
    "print(f'There are {len(df_yearly)} entries left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add raw bias\n",
    "for m in minorities:\n",
    "        df_yearly[f'raw_bias_{m}'] = df_yearly[m] / df_yearly['total']\n",
    "\n",
    "# compute medians\n",
    "raw_bias_medians = { m : df_yearly[f'raw_bias_{m}'].median() for m in minorities}\n",
    "\n",
    "# add bias\n",
    "for m in minorities:\n",
    "    df_yearly[f'bias_{m}'] = df_yearly[f'raw_bias_{m}'] - raw_bias_medians[m]\n",
    "\n",
    "df_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df = df_yearly.merge(df_officers, how='left', left_index=True, right_index=True, validate='one_to_one')\n",
    "bias_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have the biases and the officer characteristics, let's look at it more closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = ['bias_black', 'bias_white', 'bias_hispanic']\n",
    "mapping = dict(zip(minorities, ['k'; 'r', 'y']))\n",
    "medians = {}\n",
    "for m in minorities:\n",
    "    medians[color] = bias_df.loc[bias_df['officer_race'] == color, percents].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, m in enumerate(minorities):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    axs = sns.barplot(x = m, y = medians[m], color=mapping[m])\n",
    "    axs.set_ylim(0, 0.7)\n",
    "    plt.title(color + ' officer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's fit a linear regression to study a potential link between the officer features and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models\n",
    "for m in minorities:\n",
    "    print()\n",
    "    print(f'--------------{m.upper()}--------------')\n",
    "    res = smf.ols(formula=f'bias_{m} ~ C(officer_race) + C(officer_sex) + officer_age', data=bias_df).fit()\n",
    "    print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- The results are the opposite of what was expected : the bias score toward a minority m increases when the officer is of the same race\n",
    "- The age seems to diminish the bias score of the officer\n",
    "\n",
    "**Conclusion**\n",
    "- The assumption \"median of raw biases toward m = proportion of m in the local population\" does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of counties in which an officer appears\n",
    "county_per_officer = df_full.groupby('officer_id_hash')['county_name'].nunique()\n",
    "sns.histplot(county_per_officer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "All officers have more than 1 county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = County_score></a>\n",
    "# County adjusted bias score.\n",
    "\n",
    "## Goal\n",
    "\n",
    "We previously attempted to define a statewide bias score to study the influence of officer's characteristics. <br/>\n",
    "It is possible that differences in the the racial repartition of local population influence this score. In order to get rid of this effect, we tried to normalise the scores by county.\n",
    "\n",
    "However, we noticed that officers often operate on multiple counties. Hence, it was not possible to just assign an officer to a county to adjust the scores. This is why the score will now be adjusted according to the county where *each stop* occures. \n",
    "\n",
    "In summary, each officer will have a \"county score\", and his bias score will be the mean of these scores, weighted by the proportion of stops he made in each counties.\n",
    "\n",
    "The county score is the relative variation from the mean in the county.\n",
    "\n",
    "For the county $c$ and minority $m$, we denote $x_{c, m} = \\frac{\\text{Number of stops of}~m~\\text{in}~c}{\\text{Total number of stops over the period in}~c}$\n",
    "\n",
    "For officer $o$, we denote $p_{c, m, o} = \\frac{\\text{Number of stops of}~m~\\text{in}~c~\\text{by}~o}{\\text{Total number of stops over the period in}~c~\\text{by}~o}$\n",
    "\n",
    "\n",
    "Finally, $N_o$ is the total number of stops by officer $o$, and $N_{o, c}$ is the number of stops by $o$ in county $c$.\n",
    "\n",
    "We can now define an adjusted bias score for officer $o$ towards minority $m$ :\n",
    "\n",
    "$$\\boxed{\\text{Score}_{o, m} = \\frac{1}{N_o}\\sum_c\\left( N_{o,c} \\cdot \\frac{p_{c, m, o} - x_{c, m}}{x_{c, m}} \\right)}$$\n",
    "\n",
    "*N.B.* : minority denotes here only an ethnie, no matter the percentage of the population it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_year_hash(df):\n",
    "    df['officer_hash_year'] = df['officer_id_hash'] + '-' + df['year'].astype(str)\n",
    "\n",
    "#Used to compute the score of an officer\n",
    "def score_by_county(officer_df, minority, county_means, relative = True):\n",
    "    county_stop_proportion_minority = officer_df.groupby('county_name')[minority + '_stoped'].mean()\n",
    "    county_stop_count = officer_df.groupby('county_name')[minority + '_stoped'].count()\n",
    "    county_stop_prop = county_stop_count/county_stop_count.sum()\n",
    "    if (relative is True):\n",
    "        return (((county_stop_proportion_minority - county_means[minority].loc[county_stop_proportion_minority.index])/county_means[minority].loc[county_stop_proportion_minority.index])*county_stop_prop).sum()\n",
    "    else:\n",
    "        return ((county_stop_proportion_minority - county_means[minority].loc[county_stop_proportion_minority.index])*county_stop_prop).sum()\n",
    "    \n",
    "def age_map(x):\n",
    "    if (x < 32):\n",
    "        return \"young\"\n",
    "    elif(x > 50):\n",
    "        return \"old\"\n",
    "    else:\n",
    "        return \"middle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of a hash by officer and year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full.copy()\n",
    "create_year_hash(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_required = 300\n",
    "\n",
    "print(\"{:.0f}% of officers have enough stops.\".format((df.groupby('officer_hash_year')['date'].count() > stops_required).mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officers_to_keep = df.groupby('officer_hash_year')['year'].count().loc[df.groupby('officer_hash_year')['year'].count() > stops_required].index\n",
    "\n",
    "df = df[df.officer_hash_year.isin(officers_to_keep)]\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for minority in minorities:\n",
    "    df[minority + '_stoped'] = (df['subject_race'] == minority)\n",
    "\n",
    "#Computation the % of stops for each minority in each county\n",
    "county_means = {}\n",
    "for minority in minorities:\n",
    "    county_means[minority] = df.groupby('county_name')[minority + '_stoped'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation of the bias scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for minority in tqdm(minorities):\n",
    "    scores[minority] = df.groupby('officer_hash_year').apply(score_by_county, minority, county_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's link these scores to the officers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officer_numerics = ['officer_age', 'officer_years_of_service']\n",
    "officer_cat = ['officer_race', 'officer_sex']\n",
    "\n",
    "# Create a dataframe with the characteristics of officers.\n",
    "officer_df = df.groupby('officer_hash_year')[officer_numerics].mean()\n",
    "\n",
    "officer_df[officer_cat] = (df[['officer_hash_year'] + officer_cat].drop_duplicates()).set_index('officer_hash_year')\n",
    "\n",
    "# Add the bias score\n",
    "for minority in minorities:\n",
    "    officer_df[minority + '_bias'] = scores[minority]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once again, let's perform regressions to study the link between officer characteristics and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for minority in minorities:\n",
    "    print()\n",
    "    print(f'--------------{minority.upper()}--------------')\n",
    "    res = smf.ols(formula=f'{minority}_bias ~ C(officer_race) + C(officer_sex) + officer_age + officer_years_of_service', data=officer_df).fit()\n",
    "    print(res.summary())\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There does not seem to be a statistically significant link between the parameters considered and the score defined. Let's look directly at the distribution of scores according to the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = ['white_bias', 'hispanic_bias', 'black_bias']\n",
    "\n",
    "minorities = ['white', 'hispanic', 'black']\n",
    "sexes = ['male', 'female']\n",
    "ages = ['young', 'middle', 'old']\n",
    "\n",
    "choice_params = {'minority':minorities, 'sex':sexes, 'age': ages}\n",
    "choice_category = {'minority':'officer_race', 'sex': 'officer_sex', 'age': 'officer_generation'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = officer_df['officer_age'].apply(age_map)\n",
    "\n",
    "officer_df['officer_generation'] = generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'age' #Possibilities : 'age', 'sex', 'minority'\n",
    "\n",
    "for bias in biases:\n",
    "    axs =  plt.axes()\n",
    "    for m in choice_params[choice]:\n",
    "        sns.kdeplot(officer_df[officer_df[choice_category[choice]] == m][bias], label = m + \" officers\", ax = axs)\n",
    "    axs.axvline(x=0, ymin=0, ymax=100, linestyle='dashed', color = 'grey')\n",
    "    axs.set_xlim([-1.5,2])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'hispanic': 'y', \n",
    "          'black': 'k', \n",
    "          'white':'r'}\n",
    "colors = [mapping[r] for r in officer_df['officer_race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter(officer_df['white_bias'],officer_df['black_bias'], officer_df['hispanic_bias'] , color=colors)\n",
    "ax.set_xlabel('white_bias')\n",
    "ax.set_ylabel('black_bias')\n",
    "ax.set_zlabel('hispanic_bias')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matlplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(officer_df.corr().loc[officer_numerics, biases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From those visualisations, there is no clear link between any of the parameters we chose and the defined bias score. \n",
    "\n",
    "This can be interpreted 2 different ways:\n",
    "- The first differences were due to repartitions of population, which is why there were more officers stopping drivers of their own race.\n",
    "- There is indeed a direct link between the characteristics and a bias, and a more adjusted metric could show it.\n",
    "\n",
    "## Use of another metric:\n",
    "\n",
    "The authors of the paper from which this work started used different kinds of metrics, in an atempt to produce objective results. We will try to use the veil of darkness that they introduced, with a light on the differences in this metric when the officer's characteristics are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO : notebook Jonas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = Veil_of_darkness></a>\n",
    "# Veil of darness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
